apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: gwas-template
spec:
  entrypoint: gwas-workflow

  templates:
    - name: gwas-workflow
      inputs:
        parameters:
          - name: internal_api_env
            default: default
          - name: source_id
          - name: case_cohort_definition_id
          - name: control_cohort_definition_id
            default: -1
          - name: hare_concept_id
            default: 2000007027
          - name: hare_population
          - name: n_pcs
            default: 0
          - name: variables
          - name: out_prefix
            value: vadc_genesis
          - name: outcome
            default: -1
          - name: pca_file
          - name: relatedness_matrix_file
          - name: genome_build
            enum:
              - "hg38"
              - "hg19"
            default: "hg19"
          - name: n_segments
            default: 0
          - name: segment_length
            default: 10000
          - name: variant_block_size
            default: 1024
          - name: mac_threshold
          - name: maf_threshold
            default: 0.01
          - name: imputation_score_cutoff
            default: 0.03
          - name: gds_files

      dag:
        tasks:
          - name: process-variables
            template: get-variable-json
            arguments:
              parameters:
                - name: source_id
                  value: "{{inputs.parameters.source_id}}"
                - name: hare_concept_id
                  value: "{{inputs.parameters.hare_concept_id}}"
                - name: outcome
                  value: "{{inputs.parameters.outcome}}"
                - name: variables
                  value: "{{inputs.parameters.variables}}"

          - name: get-pheno-csv
            template: get-cohort-middleware-pheno-csv
            dependencies: [process-variables]
            arguments:
              parameters:
                - name: source_id
                  value: "{{inputs.parameters.source_id}}"
                - name: case_cohort_id
                  value: "{{inputs.parameters.case_cohort_definition_id}}"
                - name: control_cohort_id
                  value: "{{inputs.parameters.control_cohort_definition_id}}"
                - name: internal_api_env
                  value: "{{inputs.parameters.internal_api_env}}"
              artifacts:
                - name: variables_json
                  from: "{{tasks.process-variables.outputs.artifacts.variables_with_hare_json}}"

          - name: generate-pheno
            template: generate-pheno
            dependencies: [get-pheno-csv]
            arguments:
              parameters:
                - name: prefixed_hare_concept_id
                  value: "ID_{{inputs.parameters.hare_concept_id}}"
                - name: hare_population 
                  value: "{{inputs.parameters.hare_population}}"
              artifacts:
                - name: pheno_csv
                  from: "{{tasks.get-pheno-csv.outputs.artifacts.pheno_csv}}"

          - name: run-impute-score-filter
            template: impute-score-filter
            dependencies: [generate-pheno]
            arguments:
              parameters:
                - name: impute_cutoff
                  value: "{{inputs.parameters.imputation_score_cutoff}}"
                - name: gds_file
                  value: "{{item}}"
            withParam: "{{=toJson(map(jsonpath(inputs.parameters.gds_files, '$'), {#}))}}"

          - name: run-null-model
            template: run-null-model
            dependencies: [generate-pheno]
            arguments:
              parameters:
                - name: n_pcs
                  value: "{{inputs.parameters.n_pcs}}"
                - name: covariates
                  value: "{{tasks.process-variables.outputs.parameters.covariates}}"
                - name: out_prefix
                  value: "{{inputs.parameters.out_prefix}}_null_model"
                - name: outcome
                  value: "{{= inputs.parameters.control_cohort_definition_id == '-1' ? 'ID_' + inputs.parameters.outcome : 'CASE_CONTROL' }}"
                - name: outcome_is_binary
                  value: "{{= inputs.parameters.control_cohort_definition_id == '-1' ? 'FALSE' : 'TRUE' }}"
                - name: pca_file
                  value: "{{inputs.parameters.pca_file}}"
                - name: relatedness_matrix_file
                  value: "{{inputs.parameters.relatedness_matrix_file}}"
              artifacts:
                - name: phenotype_file
                  from: "{{tasks.generate-pheno.outputs.artifacts.phenotype_file}}"

          - name: define-segments
            template: define-segments
            arguments:
              parameters:
                - name: genome_build
                  value: "{{inputs.parameters.genome_build}}"
                - name: n_segments
                  value: "{{inputs.parameters.n_segments}}"
                - name: segment_length
                  value: "{{inputs.parameters.segment_length}}"

          - name: split-filename
            template: split-filename
            arguments:
              parameters:
                - name: gds_file
                  value: "{{=map(jsonpath(inputs.parameters.gds_files, '$'), {#})[0]}}"

          - name: filter-segments
            template: filter-segments
            dependencies: [define-segments, split-filename]
            arguments:
              parameters:
                - name: file_prefix
                  value: "{{=jsonpath(tasks['split-filename'].outputs.result, '$.file_prefix')}}"
                - name: file_suffix
                  value: "{{=jsonpath(tasks['split-filename'].outputs.result, '$.file_suffix')}}"
                - name: gds_filenames
                  value: "{{inputs.parameters.gds_files}}"
              artifacts:
                - name: segment_file
                  from: "{{tasks.define-segments.outputs.artifacts.segment_file}}"

          - name: run-single-assoc
            template: run-single-assoc
            dependencies: [run-null-model, filter-segments, split-filename, run-impute-score-filter]
            arguments:
              parameters:
                - name: file_prefix
                  value: "{{=jsonpath(tasks['split-filename'].outputs.result, '$.file_prefix')}}"
                - name: file_suffix
                  value: "{{=jsonpath(tasks['split-filename'].outputs.result, '$.file_suffix')}}"
                - name: gds_files
                  value: "{{inputs.parameters.gds_files}}"
                - name: genome_build
                  value: "{{inputs.parameters.genome_build}}"
                - name: out_prefix
                  value: "{{inputs.parameters.out_prefix}}"
                - name: variant_block_size
                  value: "{{inputs.parameters.variant_block_size}}"
                - name: outcome_is_binary
                  value: "{{= inputs.parameters.control_cohort_definition_id == '-1' ? 'FALSE' : 'TRUE' }}"
                - name: mac_threshold
                  value: "{{inputs.parameters.mac_threshold}}"
                - name: maf_threshold
                  value: "{{inputs.parameters.maf_threshold}}"
                - name: segment
                  value: "{{item}}"
              artifacts:
                - name: segment_file
                  from: "{{tasks.define-segments.outputs.artifacts.segment_file}}"
                - name: phenotype_file
                  from: "{{tasks.run-null-model.outputs.artifacts.null_model_phenotype}}"
                - name: null_model_results
                  from: "{{tasks.run-null-model.outputs.artifacts.null_model_directory}}"
                - name: variant_list_dir
                  s3:
                    key: "{{workflow.name}}/variant_lists"
            withParam: "{{=toJson(jsonpath(tasks['filter-segments'].outputs.result, '$.segments'))}}"

          - name: combine-shards
            template: combine-shards
            dependencies: [run-single-assoc]
            arguments:
              parameters:
                - name: chromosome
                  value: "{{item}}"
                - name: out_prefix
                  value: "{{inputs.parameters.out_prefix}}"
              artifacts:
                - name: file_shards
                  s3:
                    key: "{{workflow.name}}/single_assoc_chunks"
            withParam: "{{=toJson(jsonpath(tasks['filter-segments'].outputs.result, '$.chromosomes'))}}"

          - name: run-plots
            template: run-plots
            dependencies: [combine-shards]
            arguments:
              parameters:
                - name: chromosomes
                  value: "{{=sprig.join(' ', jsonpath(tasks['filter-segments'].outputs.result, '$.chromosomes'))}}"
                - name: out_prefix
                  value: "{{inputs.parameters.out_prefix}}"
              artifacts:
                - name: combined
                  s3:
                    key: "{{workflow.name}}/single_assoc_combined"

          - name: annotate-statistics
            template: run-annotate
            dependencies: [combine-shards]
            arguments:
              parameters:
                - name: chromosome
                  value: "{{item}}"
                - name: out_prefix
                  value: "{{inputs.parameters.out_prefix}}"
              artifacts:
                - name: raw_stats
                  s3:
                    key: "{{workflow.name}}/single_assoc_combined/{{inputs.parameters.out_prefix}}_chr{{item}}.RData"
            withParam: "{{=toJson(jsonpath(tasks['filter-segments'].outputs.result, '$.chromosomes'))}}"

          - name: generate-gwas-metadata
            template: get-gwas-metadata
            dependencies: [process-variables]
            arguments:
              parameters:
                - name: source_id
                  value: "{{inputs.parameters.source_id}}"
                - name: case_cohort_id
                  value: "{{inputs.parameters.case_cohort_definition_id}}"
                - name: control_cohort_id
                  value: "{{inputs.parameters.control_cohort_definition_id}}"
                - name: outcome_concept_id
                  value: "{{inputs.parameters.outcome}}"
                - name: internal_api_env
                  value: "{{inputs.parameters.internal_api_env}}"
                - name: n_pcs
                  value: "{{inputs.parameters.n_pcs}}"
                - name: maf_threshold
                  value: "{{inputs.parameters.maf_threshold}}"
                - name: imputation_score_cutoff
                  value: "{{inputs.parameters.imputation_score_cutoff}}"
                - name: hare_population
                  value: "{{inputs.parameters.hare_population}}"
              artifacts:
                - name: variables_json
                  from: "{{tasks.process-variables.outputs.artifacts.raw_variables_json}}"

          - name: generate-attrition-csv
            template: get-attrition-csv
            dependencies: [process-variables]
            arguments:
              parameters:
                - name: source_id
                  value: "{{inputs.parameters.source_id}}"
                - name: case_cohort_id
                  value: "{{inputs.parameters.case_cohort_definition_id}}"
                - name: control_cohort_id
                  value: "{{inputs.parameters.control_cohort_definition_id}}"
                - name: breakdown_concept_id 
                  value: "{{inputs.parameters.hare_concept_id}}"
                - name: internal_api_env
                  value: "{{inputs.parameters.internal_api_env}}"
              artifacts:
                - name: variables_json
                  from: "{{tasks.process-variables.outputs.artifacts.raw_variables_json}}"

          - name: archive-outputs
            template: run-tar
            dependencies: [run-plots, annotate-statistics, generate-gwas-metadata, generate-attrition-csv]
            arguments:
              parameters:
                - name: out_prefix
                  value: "{{inputs.parameters.out_prefix}}"
              artifacts:
                - name: manhattan_plot
                  from: "{{tasks.run-plots.outputs.artifacts.manhattan_plot}}"
                - name: qq_plot 
                  from: "{{tasks.run-plots.outputs.artifacts.qq_plot}}"
                - name: annotated_csvs
                  s3:
                    key: "{{workflow.name}}/annotated_csvs"
                - name: gwas_metadata
                  from: "{{tasks.generate-gwas-metadata.outputs.artifacts.gwas_metadata}}"
                - name: attrition_csvs
                  from: "{{tasks.generate-attrition-csv.outputs.artifacts.attrition_table_directory}}"

          - name: create-indexd-record
            template: create-indexd-record
            dependencies: [archive-outputs]
            arguments:
              parameters:
                - name: arborist_resource
                  value: "/cohort-middleware"
                - name: internal_api_env
                  value: "{{inputs.parameters.internal_api_env}}"
              artifacts:
                - name: gwas_archive
                  from: "{{tasks.archive-outputs.outputs.artifacts.gwas_archive}}"

    - name: get-variable-json
      inputs:
        parameters:
          - name: variables
          - name: hare_concept_id
          - name: outcome
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"
      script:
        image: quay.io/cdis/alpine-jq:latest
        command: [sh]
        source: |
          echo '{{inputs.parameters.variables}}' | jq . > /mnt/vol/raw_variables.json
          echo '{{inputs.parameters.variables}}' | jq '. += [{"variable_type": "concept", "concept_id": {{inputs.parameters.hare_concept_id}} }]' > /mnt/vol/variables_with_hare.json

          CONCEPT_VARS=""

          if [ "{{inputs.parameters.outcome}}" = "-1" ]; then
                  CONCEPT_VARS=`echo '{{inputs.parameters.variables}}' | jq '.[] | select( .concept_id != null ) | ["ID_\(.concept_id)"]' | jq -rs 'flatten(1) | join(" ")'`
          else
                  CONCEPT_VARS=`echo '{{inputs.parameters.variables}}' | jq '.[] | select( .concept_id != null and .concept_id != {{inputs.parameters.outcome}} ) | ["ID_\(.concept_id)"]' | jq -rs 'flatten(1) | join(" ")'`
          fi

          DICHOTOMOUS_VARS=""
          CURR=`echo '{{inputs.parameters.variables}}' | jq '.[] | select( .variable_type == "custom_dichotomous" ) | .cohort_ids | map(tostring) | join("_") | "ID_\(.)"' | jq -rs 'flatten(1) | join(" ")'`
          if [ -z $CURR ]; then
                  DICHOTOMOUS_VARS=""
          elif [ -z $CONCEPT_VARS ]; then
                  DICHOTOMOUS_VARS="${CURR}"
          else
                  DICHOTOMOUS_VARS=" ${CURR}"
          fi

          echo -n "${CONCEPT_VARS}${DICHOTOMOUS_VARS}" > /mnt/vol/covariate_string.txt
        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
      outputs:
        parameters:
          - name: covariates
            valueFrom:
                path: /mnt/vol/covariate_string.txt
        artifacts:
          - name: raw_variables_json
            path: /mnt/vol/raw_variables.json
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/{{pod.name}}/{{workflow.name}}.raw_variables.json"
          - name: variables_with_hare_json
            path: /mnt/vol/variables_with_hare.json
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/{{pod.name}}/{{workflow.name}}.variables_with_hare.json"

    - name: get-cohort-middleware-pheno-csv
      inputs:
        parameters:
          - name: source_id
          - name: case_cohort_id
          - name: control_cohort_id
          - name: internal_api_env
        artifacts:
          - name: variables_json
            path: "/mnt/vol/variables.json"
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"
      script:
        image: quay.io/cdis/vadc-gwas-tools:0.2.1
        imagePullPolicy: Always
        command: [/bin/bash]
        source: |
          if [[ "{{inputs.parameters.control_cohort_id}}" == "-1" ]]; then
              CONTROL_COHORT=""
          else
              CONTROL_COHORT=" --control_cohort_id {{inputs.parameters.control_cohort_id}}"
          fi

          /env/bin/vadc-gwas-tools GetCohortPheno \
          --source_id {{inputs.parameters.source_id}} \
          --case_cohort_id {{inputs.parameters.case_cohort_id}}${CONTROL_COHORT} \
          --variables_json {{inputs.artifacts.variables_json.path}} \
          --output /mnt/vol/{{workflow.name}}.pheno.csv.gz

        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
        resources:
          requests:
            cpu: 500m
            memory: 500Mi
          limits:
            cpu: 1000m
            memory: 1Gi
        env:
          - name: GEN3_ENVIRONMENT
            value: "{{inputs.parameters.internal_api_env}}"
      outputs:
        artifacts:
          - name: pheno_csv
            path: /mnt/vol/{{workflow.name}}.pheno.csv.gz
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/{{pod.name}}/{{workflow.name}}.pheno.csv.gz"

    - name: generate-pheno
      inputs:
        parameters:
          - name: prefixed_hare_concept_id
          - name: hare_population
        artifacts:
          - name: pheno_csv
            mode: 0777
            path: "/mnt/vol/phenotypes.csv.gz"
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"
      script:
        image: quay.io/cdis/topmed-master:2.12.0
        imagePullPolicy: IfNotPresent
        command: [Rscript]
        source: |
          library(Biobase)

          dat.csv <- read.csv(gzfile("{{inputs.artifacts.pheno_csv.path}}"),
                              stringsAsFactors=FALSE, na.strings=c("NA", ""))
          stopifnot("sample.id" %in% names(dat.csv))
          dat.csv$sample.id <- as.character(dat.csv$sample.id)

          # Filter to HARE population
          dat.csv <- subset(dat.csv, {{inputs.parameters.prefixed_hare_concept_id}} == "{{inputs.parameters.hare_population}}")

          # Remove NAs
          dat.csv <- na.omit(dat.csv)

          # Convert to AnnotatedDataFrame
          annot <- AnnotatedDataFrame(dat.csv)
          stopifnot("sample.id" %in% varLabels(annot))
          save(annot, file="/mnt/vol/phenotypes.Rdata")

        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
        resources:
          requests:
            cpu: 500m
            memory: 512Mi
          limits:
            cpu: 1000m
            memory: 2Gi
      outputs:
        artifacts:
          - name: phenotype_file
            path: "/mnt/vol/phenotypes.Rdata"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/{{pod.name}}/phenotypes.Rdata"

    - name: impute-score-filter
      inputs:
        parameters:
          - name: impute_cutoff
          - name: gds_file
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"
      script:
        image: quay.io/cdis/topmed-master:2.12.0
        imagePullPolicy: IfNotPresent
        command: [Rscript]
        source: |
          library(SeqVarTools)

          gdsFile <- "{{inputs.parameters.gds_file}}"
          imputation.cutoff <- {{inputs.parameters.impute_cutoff}}
          chrom <- gsub("(.*)(chr[0-9X]+)(.*)", "\\2", basename(gdsFile))
          cat("gds:", gdsFile, "chromosome:", chrom, "\n")

          dir.create("/mnt/vol/variant_lists")
          outFile <- file.path("/mnt/vol/variant_lists", paste0(chrom, ".selected_variants.RData"))

          gds <- seqOpen(gdsFile)

          all.variant.ids <- seqGetData(gds, "variant.id")
          imputation.fit <- seqGetData(gds, "annotation/info/R2")
          sel <- imputation.fit >= imputation.cutoff | is.na(imputation.fit)
          variant.ids <- all.variant.ids[sel]
          save(variant.ids, file=outFile)
          seqClose(gds)
          
          cat("Total variants:", length(all.variant.ids),
              "\nDropped variants:", length(all.variant.ids) - length(variant.ids),
              "\nRemaining variants (%):", length(variant.ids),
                  paste0("(", round(100*(length(variant.ids)/length(all.variant.ids)), 2), "%)"), "\n")

        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
          - name: gateway
            mountPath: /commons-data
        resources:
          requests:
            cpu: 500m
            memory: 512Mi
          limits:
            cpu: 1000m
            memory: 2Gi
      outputs:
        artifacts:
          - name: variant_list_dir
            path: "/mnt/vol/variant_lists"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/variant_lists"


    - name: run-null-model
      inputs:
        parameters:
          - name: n_pcs
          - name: covariates
          - name: out_prefix
          - name: outcome
          - name: outcome_is_binary
          - name: pca_file
          - name: relatedness_matrix_file
        artifacts:
          - name: phenotype_file
            mode: 0777
            path: "/mnt/vol/phenotypes.Rdata"
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"

      script:
        image: quay.io/cdis/topmed-master:2.12.0
        imagePullPolicy: IfNotPresent
        command: [bash]
        source: |
          export NSLOTS=2
          cd /mnt/vol


          echo "out_prefix {{inputs.parameters.out_prefix}}" > null_model.config
          echo "phenotype_file {{inputs.artifacts.phenotype_file.path}}" >> null_model.config
          echo "outcome {{inputs.parameters.outcome}}" >> null_model.config
          if [[ "{{inputs.parameters.outcome_is_binary}}" == "TRUE" ]]; then
                echo "family \"binomial\"" >> null_model.config
          else
                echo "family \"gaussian\"" >> null_model.config
          fi
          echo "n_pcs {{inputs.parameters.n_pcs}}" >> null_model.config
          echo "pca_file {{inputs.parameters.pca_file}}" >> null_model.config
          echo "relatedness_matrix_file {{inputs.parameters.relatedness_matrix_file}}" >> null_model.config

          if [[ -z "{{inputs.parameters.covariates}}" ]]; then
              echo "No covariates provided."
          else
              echo "covars \"{{inputs.parameters.covariates}}\"" >> null_model.config
          fi
          echo "out_phenotype_file {{inputs.parameters.out_prefix}}_phenotypes.Rdata" >> null_model.config

          set -xe
          cat null_model.config

          Rscript /usr/local/analysis_pipeline/R/null_model.R null_model.config
          Rscript /usr/local/analysis_pipeline/R/null_model_report.R null_model.config --version 2.12.0
          ls -al

          DATADIR={{inputs.parameters.out_prefix}}_datadir
          mkdir $DATADIR
          mv {{inputs.parameters.out_prefix}}*.RData $DATADIR/

          REPORTDIR={{inputs.parameters.out_prefix}}_reports
          mkdir $REPORTDIR
          mv *.html $REPORTDIR/
          mv *.Rmd $REPORTDIR/

        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
          - name: gateway
            mountPath: /commons-data

        resources:
          requests:
            cpu: 2500m
            memory: 2Gi
          limits:
            cpu: 5000m
            memory: 5Gi

      outputs:
        artifacts:
          - name: null_model_directory
            path: "/mnt/vol/{{inputs.parameters.out_prefix}}_datadir"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/{{pod.name}}/{{inputs.parameters.out_prefix}}_datadir"
          - name: null_model_phenotype
            path: "/mnt/vol/{{inputs.parameters.out_prefix}}_phenotypes.Rdata"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/{{pod.name}}/{{inputs.parameters.out_prefix}}_phenotypes.Rdata"
          - name: null_model_report_directory
            path: "/mnt/vol/{{inputs.parameters.out_prefix}}_reports"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/{{pod.name}}/{{inputs.parameters.out_prefix}}_reports"

    - name: define-segments
      inputs:
        parameters:
          - name: genome_build
          - name: n_segments
          - name: segment_length
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"

      script:
        image: quay.io/cdis/topmed-master:2.12.0
        imagePullPolicy: IfNotPresent
        command: [bash]
        source: |
          cd /mnt/vol
          echo "genome_build {{inputs.parameters.genome_build}}" > define_segments.config
          echo "out_file segments.txt" >> define_segments.config

          if [[ "{{inputs.parameters.n_segments}}" == "0" ]]; then
              NSEG=""
          else
              NSEG=" --n_segments {{inputs.parameters.n_segments}}"
          fi

          Rscript /usr/local/analysis_pipeline/R/define_segments.R \
          define_segments.config \
          --segment_length {{inputs.parameters.segment_length}}${NSEG}

        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol

        resources:
          requests:
            cpu: 250m
            memory: 512Mi
          limits:
            cpu: 500m
            memory: 1Gi

      outputs:
        artifacts:
          - name: segment_file
            path: "/mnt/vol/segments.txt"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/{{pod.name}}/segments.txt"

    - name: split-filename
      inputs:
        parameters:
          - name: gds_file
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"
      container:
        image: quay.io/cdis/vadc-gwas-tools:0.2.1
        imagePullPolicy: Always
        command: ["/bin/bash", "-c"]
        args: ["/env/bin/vadc-gwas-tools SplitFilenameByChr \
          --gds_file {{inputs.parameters.gds_file}}
        "]
        resources:
          requests:
            cpu: 50m
            memory: 50Mi
          limits:
            cpu: 100m
            memory: 100Mi

    - name: filter-segments
      inputs:
        parameters:
          - name: gds_filenames
          - name: file_prefix
          - name: file_suffix
        artifacts:
          - name: segment_file
            path: "/mnt/vol/segments.txt"
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"
      container:
        image: quay.io/cdis/vadc-gwas-tools:0.2.1
        imagePullPolicy: Always
        command: ["/bin/bash", "-c"]
        args: ["/env/bin/vadc-gwas-tools FilterSegments \
          --file_prefix {{inputs.parameters.file_prefix}} \
          --file_suffix {{inputs.parameters.file_suffix}} \
          --segment_file {{inputs.artifacts.segment_file.path}} \
          {{=sprig.join(' ', map(jsonpath(inputs.parameters.gds_filenames, '$'), {#}))}}
        "]
        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
        resources:
          requests:
            cpu: 50m
            memory: 50Mi
          limits:
            cpu: 100m
            memory: 100Mi

    - name: run-single-assoc
      inputs:
        parameters:
          - name: gds_files
          - name: out_prefix
          - name: genome_build
          - name: file_prefix
          - name: file_suffix
          - name: segment
          - name: variant_block_size
          - name: mac_threshold
          - name: maf_threshold
          - name: outcome_is_binary
        artifacts:
          - name: segment_file
            mode: 0777
            path: "/mnt/vol/segments.txt"
          - name: null_model_results
            mode: 0777
            path: "/mnt/vol/null_model_results"
          - name: phenotype_file
            mode: 0777
            path: "/mnt/vol/phenotypes.RData"
          - name: variant_list_dir
            mode: 0777
            path: "/mnt/vol/variant_lists"
      retryStrategy:
        limit: "5"
        retryPolicy: "Always"

      script:
        image: quay.io/cdis/topmed-master:2.12.0
        imagePullPolicy: IfNotPresent
        securityContext:
          runAsUser: 0
        command: [bash]
        source: |
          cd /mnt/vol
          for fil in {{=sprig.join(" ", map(jsonpath(inputs.parameters.gds_files, '$'), {#}))}}; do
              ln -s $fil .
          done

          set -xe
          CHROM="$(awk 'NR=={{=asInt(inputs.parameters.segment) + 1}} {print $1}' {{inputs.artifacts.segment_file.path}})" 
          echo $CHROM

          echo "out_prefix {{inputs.parameters.out_prefix}}" > assoc_single.config
          echo "genome_build {{inputs.parameters.genome_build}}" >> assoc_single.config
          echo "gds_file \"{{inputs.parameters.file_prefix}} {{inputs.parameters.file_suffix}}\"" >> assoc_single.config
          echo "phenotype_file {{inputs.artifacts.phenotype_file.path}}" >> assoc_single.config
          echo "segment_file {{inputs.artifacts.segment_file.path}}" >> assoc_single.config
          echo "variant_block_size {{inputs.parameters.variant_block_size}}" >> assoc_single.config
          echo "variant_include_file {{inputs.artifacts.variant_list_dir.path}}/chr${CHROM}.selected_variants.RData" >> assoc_single.config
          if [[ "{{inputs.parameters.outcome_is_binary}}" == "TRUE" ]]; then
                echo "null_model_file {{inputs.artifacts.null_model_results.path}}/{{inputs.parameters.out_prefix}}_null_model.RData" >> assoc_single.config
                echo "test_type \"score.spa\"" >> null_model.config
          else
                echo "null_model_file {{inputs.artifacts.null_model_results.path}}/{{inputs.parameters.out_prefix}}_null_model_invnorm.RData" >> assoc_single.config
          fi

          if [[ "{{inputs.parameters.mac_threshold}}" == "0" ]]; then
              echo "mac_threshold NA" >> assoc_single.config
              echo "maf_threshold {{inputs.parameters.maf_threshold}}" >> assoc_single.config
          else
              echo "mac_threshold {{inputs.parameters.mac_threshold}}" >> assoc_single.config
          fi

          cat assoc_single.config
          ls -al

          Rscript /usr/local/analysis_pipeline/R/assoc_single.R assoc_single.config --chromosome $CHROM \
          --segment {{inputs.parameters.segment}} \
          --num_cores 1

          SEGOUT="{{inputs.parameters.out_prefix}}_chr${CHROM}_seg{{inputs.parameters.segment}}.RData"
          mkdir single_assoc_chunks

          if [[ -f $SEGOUT ]]; then
                mv $SEGOUT single_assoc_chunks/
          else
                echo "No outputs for segment... skipping..."
          fi

        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
          - name: gateway
            mountPath: /commons-data

        resources:
          requests:
            cpu: 1000m
            memory: 4Gi
          limits:
            cpu: 2000m
            memory: 8Gi
      outputs:
        artifacts:
          - name: single_assoc_segment_output
            path: "/mnt/vol/single_assoc_chunks"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/single_assoc_chunks"

    - name: combine-shards
      inputs:
        parameters:
          - name: chromosome
          - name: out_prefix
        artifacts:
          - name: file_shards
            mode: 0777
            path: "/mnt/vol/file_shards"
      retryStrategy:
        limit: "4"
        retryPolicy: "Always"

      script:
        image: quay.io/cdis/topmed-master:2.12.0
        imagePullPolicy: IfNotPresent
        securityContext:
          runAsUser: 0
        command: [bash]
        source: |
          cd {{inputs.artifacts.file_shards.path}}

          echo "out_prefix {{inputs.parameters.out_prefix}}" > assoc_combine.config
          echo "assoc_type \"single\"" >> assoc_combine.config

          cat assoc_combine.config
          ls -al

          set -xe
          Rscript /usr/local/analysis_pipeline/R/assoc_combine.R \
          assoc_combine.config \
          --chromosome {{inputs.parameters.chromosome}}
          mkdir single_assoc_combined
          mv {{inputs.parameters.out_prefix}}_chr{{inputs.parameters.chromosome}}.RData single_assoc_combined/

        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
        resources:
          requests:
            cpu: 1000m
            memory: 4Gi
          limits:
            cpu: 2000m
            memory: 8Gi
      outputs:
        artifacts:
          - name: single_assoc_combined
            path: "{{inputs.artifacts.file_shards.path}}/single_assoc_combined"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/single_assoc_combined"

    - name: run-plots
      inputs:
        parameters:
          - name: chromosomes
          - name: out_prefix
        artifacts:
          - name: combined
            mode: 0777
            path: "/mnt/vol/combined"
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"

      script:
        image: quay.io/cdis/topmed-master:2.12.0
        imagePullPolicy: IfNotPresent
        securityContext:
          runAsUser: 0
        command: [bash]
        source: |
          cd {{inputs.artifacts.combined.path}}

          echo "assoc_type \"single\"" > plots.config
          echo "thin \"TRUE\"" >> plots.config
          echo "assoc_file \"{{inputs.parameters.out_prefix}}_chr .RData\"" >> plots.config
          echo "chromosomes \"{{inputs.parameters.chromosomes}}\"" >> plots.config
          echo "out_file_manh \"{{inputs.parameters.out_prefix}}_manhattan.png\"" >> plots.config
          echo "out_file_qq \"{{inputs.parameters.out_prefix}}_qq.png\"" >> plots.config

          cat plots.config
          ls -al

          set -xe
          Rscript /usr/local/analysis_pipeline/R/assoc_plots.R plots.config

        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
        resources:
          requests:
            cpu: 250m
            memory: 1Gi
          limits:
            cpu: 1000m
            memory: 8Gi
      outputs:
        artifacts:
          - name: manhattan_plot
            path: "{{inputs.artifacts.combined.path}}/{{inputs.parameters.out_prefix}}_manhattan.png"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/gwas_plots/{{inputs.parameters.out_prefix}}_manhattan.png"
          - name: qq_plot
            path: "{{inputs.artifacts.combined.path}}/{{inputs.parameters.out_prefix}}_qq.png"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/gwas_plots/{{inputs.parameters.out_prefix}}_qq.png"

    - name: run-annotate
      inputs:
        parameters:
          - name: chromosome
          - name: out_prefix
        artifacts:
          - name: raw_stats
            mode: 0777
            path: "/mnt/vol/raw_stats.RData"
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"

      script:
        image: quay.io/cdis/topmed-master:2.12.0
        imagePullPolicy: IfNotPresent
        securityContext:
          runAsUser: 0
        command: [Rscript]
        source: |
          library(dplyr)

          # Load summary stats
          load("{{inputs.artifacts.raw_stats.path}}")

          # Load RSID meta
          anno.df <- read.delim("/commons-data/kmhernan/marker_metadata/vadc_mvp_marker_annotation.chr{{inputs.parameters.chromosome}}.rsids.tsv.gz",
                                header=TRUE,
                                stringsAsFactors=FALSE,
                                sep="\t")

          # Load var meta
          varmeta.df <- read.csv("/commons-data/kmhernan/marker_metadata/vadc_mvp_marker_annotation.chr{{inputs.parameters.chromosome}}.var_meta.csv.gz",
                                 stringsAsFactors=FALSE) %>%
            mutate(chr=as.character(chr))

          # Make annotated df
          annotated.summary.df <- varmeta.df %>%
            left_join(anno.df, by=c("variant.name"="variant.name")) %>%
            inner_join(assoc, by=c("variant.id"="variant.id", "chr"="chr", "pos"="pos")) %>%
            mutate(chr=paste0("chr", chr))

          # Write new CSV
          write.csv(annotated.summary.df,
            file=gzfile("/mnt/vol/{{inputs.parameters.out_prefix}}_chr{{inputs.parameters.chromosome}}.annotated_summary.csv.gz"),
            row.names=FALSE,
            na="")

        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
          - name: gateway
            mountPath: /commons-data
        resources:
          requests:
            cpu: 250m
            memory: 1Gi
          limits:
            cpu: 500m
            memory: 4Gi
      outputs:
        artifacts:
          - name: annotated_stats_csv
            path: "/mnt/vol/{{inputs.parameters.out_prefix}}_chr{{inputs.parameters.chromosome}}.annotated_summary.csv.gz"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/annotated_csvs/{{inputs.parameters.out_prefix}}_chr{{inputs.parameters.chromosome}}.annotated_summary.csv.gz"

    - name: get-gwas-metadata
      inputs:
        parameters:
          - name: source_id
          - name: case_cohort_id
          - name: control_cohort_id
          - name: outcome_concept_id
          - name: internal_api_env
          - name: n_pcs
          - name: maf_threshold
          - name: imputation_score_cutoff
          - name: hare_population
        artifacts:
          - name: variables_json
            path: /mnt/vol/variables.json
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"
      script:
        image: quay.io/cdis/vadc-gwas-tools:0.2.1
        imagePullPolicy: Always
        command: [/bin/bash]
        source: |
          if [[ "{{inputs.parameters.control_cohort_id}}" == "-1" ]]; then
              OUTCOME_ID=" --outcome_concept_id {{inputs.parameters.outcome_concept_id}}"
          else
              OUTCOME_ID=" --control_cohort_id {{inputs.parameters.control_cohort_id}}"
          fi

          /env/bin/vadc-gwas-tools GetGwasMetadata \
          --source_id {{inputs.parameters.source_id}} \
          --case_cohort_id {{inputs.parameters.case_cohort_id}}${OUTCOME_ID} \
          --variables_json {{inputs.artifacts.variables_json.path}} \
          --n_pcs {{inputs.parameters.n_pcs}} \
          --maf_threshold {{inputs.parameters.maf_threshold}} \
          --imputation_score_cutoff {{inputs.parameters.imputation_score_cutoff}} \
          --hare_population "{{inputs.parameters.hare_population}}" \
          --output /mnt/vol/{{workflow.name}}.gwas_metadata.yaml

        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
        env:
          - name: GEN3_ENVIRONMENT
            value: "{{inputs.parameters.internal_api_env}}"
      outputs:
        artifacts:
          - name: gwas_metadata
            path: /mnt/vol/{{workflow.name}}.gwas_metadata.yaml
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/{{pod.name}}/{{workflow.name}}.gwas_metadata.yaml"

    - name: get-attrition-csv
      inputs:
        parameters:
          - name: source_id
          - name: case_cohort_id
          - name: control_cohort_id
          - name: breakdown_concept_id
          - name: internal_api_env
        artifacts:
          - name: variables_json
            path: /mnt/vol/variables.json
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"
      script:
        image: quay.io/cdis/vadc-gwas-tools:0.2.1
        imagePullPolicy: Always
        command: ["/bin/bash"]
        source: |
          mkdir /mnt/vol/attrition_csvs
          if [[ "{{inputs.parameters.control_cohort_id}}" == "-1" ]]; then
              CONTROL_COHORT=""
          else
              CONTROL_COHORT=" --control_cohort_id {{inputs.parameters.control_cohort_id}}"
          fi

          /env/bin/vadc-gwas-tools GetCohortAttritionTable \
          --source_id {{inputs.parameters.source_id}} \
          --case_cohort_id {{inputs.parameters.case_cohort_id}}${CONTROL_COHORT} \
          --output_prefix /mnt/vol/attrition_csvs/{{workflow.name}} \
          --variables_json {{inputs.artifacts.variables_json.path}} \
          --prefixed_breakdown_concept_id {{inputs.parameters.breakdown_concept_id}}

        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
        env:
          - name: GEN3_ENVIRONMENT
            value: "{{inputs.parameters.internal_api_env}}"
      outputs:
        artifacts:
          - name: attrition_table_directory
            path: /mnt/vol/attrition_csvs
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/attrition_csvs"

    - name: run-tar
      inputs:
        parameters:
          - name: out_prefix
        artifacts:
          - name: manhattan_plot
            path: "/mnt/vol/{{workflow.name}}/{{inputs.parameters.out_prefix}}_manhattan.png"
          - name: qq_plot 
            path: "/mnt/vol/{{workflow.name}}/{{inputs.parameters.out_prefix}}_qq.png"
          - name: annotated_csvs
            mode: 0777
            path: "/mnt/vol/{{workflow.name}}/annotated_summary_csvs"
          - name: gwas_metadata
            path: "/mnt/vol/{{workflow.name}}/{{workflow.name}}.gwas_metadata.yaml"
          - name: attrition_csvs
            mode: 0777
            path: "/mnt/vol/{{workflow.name}}/attrition_tables"
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"

      script:
        image: alpine:latest
        imagePullPolicy: IfNotPresent
        command: [/bin/sh]
        source: |
          cd /mnt/vol
          tar -czf {{workflow.name}}.tar.gz {{workflow.name}}/

        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
        resources:
          requests:
            cpu: 250m
            memory: 500Mi
          limits:
            cpu: 500m
            memory: 1Gi

      outputs:
        artifacts:
          - name: gwas_archive
            path: "/mnt/vol/{{workflow.name}}.tar.gz"
            archive:
              none: {}
            s3:
              endpoint: s3.amazonaws.com
              bucket: argo-artifact-storage-downloadable 
              key: "{{workflow.name}}/{{workflow.name}}.tar.gz"
              accessKeySecret:
                name: argo-s3-creds
                key: AccessKeyId
              secretKeySecret:
                name: argo-s3-creds
                key: SecretAccessKey

    - name: create-indexd-record
      inputs:
        parameters:
          - name: arborist_resource
          - name: internal_api_env
        artifacts:
          - name: gwas_archive
            path: "/mnt/vol/{{workflow.name}}.tar.gz"
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"
      container:
        image: quay.io/cdis/vadc-gwas-tools:0.2.1
        imagePullPolicy: Always
        command: ["/bin/bash", "-c"]
        args: ["/env/bin/vadc-gwas-tools CreateIndexdRecord \
                --gwas_archive {{inputs.artifacts.gwas_archive.path}} \
                --s3_uri s3://argo-artifact-storage-downloadable/{{workflow.name}}/{{workflow.name}}.tar.gz \
                --arborist_resource {{inputs.parameters.arborist_resource}} \
                -o /mnt/vol/did.json"]
        env:
          - name: GEN3_ENVIRONMENT
            value: "{{inputs.parameters.internal_api_env}}"
          - name: INDEXDUSER
            valueFrom:
              secretKeyRef:
                name: indexd-creds
                key: user
          - name: INDEXDPASS
            valueFrom:
              secretKeyRef:
                name: indexd-creds
                key: password
        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
        resources:
          requests:
            cpu: 50m
            memory: 50Mi
          limits:
            cpu: 100m
            memory: 100Mi
      outputs:
        parameters:
          - name: gwas_archive_index
            valueFrom:
              path: /mnt/vol/did.json
            globalName: gwas_archive_index
