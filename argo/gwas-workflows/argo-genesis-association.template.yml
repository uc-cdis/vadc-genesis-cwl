apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: gwas-template
spec:
  entrypoint: gwas-workflow

  templates:
    - name: gwas-workflow
      inputs:
        parameters:
          - name: internal_api_env
            description: |
              When communicating with Gen3 APIs internally, the internal URLs can refer to
              different environments. Since argo is running in it's own namespace, we need
              to set this value. On prod that would be `default` but on QA it would be `qa-mickey`.
            default: default
          - name: source_id
            description: The source ID integer for where the cohorts are defined.
          - name: case_cohort_definition_id
            description: |
              The definition ID integer for the case cohort. If the study is a quantitative
              phenotype, then there is only one cohort which you can put here.
          - name: control_cohort_definition_id
            description: |
              The definition ID integer for the optional control cohort. If the study is a
              case-control phenotype, then provide the control cohort's ID here. If it is
              a quantitative phenotype, set this value to '-1' as the indicator of null.
            default: -1
          - name: n_pcs
            description: The number of population PCs to use as covariates.
            default: 0
          - name: covariates
            description: |
              A space-delimited list of prefixed concept IDs to use as covariates in the model.
          - name: out_prefix
            description: Prefix used on all outputs.
            value: vadc_genesis
          - name: outcome
            description: |
              The prefixed concept ID for the outcome/phenotype. If this is a case-control
              study, set this to '-1' to indicate null.
            default: -1
          - name: outcome_is_binary
            enum:
              - "TRUE"
              - "FALSE"
            default: "FALSE"
          - name: pca_file
            description: Path to the PCA R object on the gateway mount.
          - name: relatedness_matrix_file
            description: Path to the Relationship Matrix R object on the gateway mount.
          - name: genome_build
            enum:
              - "hg38"
              - "hg19"
            default: "hg19"
          - name: n_segments
            description: "Number of segments to use. Setting the `segment_length` will override this."
            default: 0
          - name: segment_length
            description: |
              The chunk size to use for scatter/gather. If you wish to instead set a specific
              number of chunks, set this value to '0' and provide a value for n_segments
            default: 10000
          - name: variant_block_size
            description: |
              The number of variants to hold in memory when doing association tests. This will
              greatly impact memory requirements and runtime depending on the cohort size and
              complexity of the model. Large cohorts we usually set to 100 to keep memory below
              16 GiB.
            default: 1024
          - name: mac_threshold
            description: |
              Minor Allele Count threshold to filter markers. If you instead want to use maf_threshold
              set this value to 0 as an indicator of null.
          - name: maf_threshold
            description: |
              Minor Allele Frequency threshold to filter markers.
            default: 0.01
          - name: imputation_score_cutoff
            description: Filter markers based on imputation score.
            default: 0.03
          - name: gds_files
            description: A stringified JSON array of GDS paths on the gateway mount.
      dag:
        tasks:
          - name: get-pheno-csv
            template: get-cohort-middleware-csv
            arguments:
              parameters:
                - name: cohort_middleware_url
                  value: "{{inputs.parameters.cohort_middleware_url}}"
                - name: cohort_middleware_body
                  value: "{{inputs.parameters.cohort_middleware_body}}"

          - name: generate-pheno
            template: generate-pheno
            dependencies: [get-pheno-csv]
            arguments:
              artifacts:
                - name: pheno_csv
                  from: "{{tasks.get-pheno-csv.outputs.artifacts.pheno_csv}}"

          - name: run-impute-score-filter
            template: impute-score-filter
            dependencies: [generate-pheno]
            arguments:
              parameters:
                - name: impute_cutoff
                  value: "{{inputs.parameters.imputation_score_cutoff}}"
                - name: gds_file
                  value: "{{item}}"
            withParam: "{{=toJson(map(jsonpath(inputs.parameters.gds_files, '$'), {#}))}}"

          - name: run-null-model
            template: run-null-model
            dependencies: [generate-pheno]
            arguments:
              parameters:
                - name: n_pcs
                  value: "{{inputs.parameters.n_pcs}}"
                - name: covariates
                  value: "{{inputs.parameters.covariates}}"
                - name: out_prefix
                  value: "{{inputs.parameters.out_prefix}}_null_model"
                - name: outcome
                  value: "{{inputs.parameters.outcome}}"
                - name: outcome_is_binary
                  value: "{{inputs.parameters.outcome_is_binary}}"
                - name: pca_file
                  value: "{{inputs.parameters.pca_file}}"
                - name: relatedness_matrix_file
                  value: "{{inputs.parameters.relatedness_matrix_file}}"
              artifacts:
                - name: phenotype_file
                  from: "{{tasks.generate-pheno.outputs.artifacts.phenotype_file}}"

          - name: define-segments
            template: define-segments
            arguments:
              parameters:
                - name: genome_build
                  value: "{{inputs.parameters.genome_build}}"
                - name: n_segments
                  value: "{{inputs.parameters.n_segments}}"
                - name: segment_length
                  value: "{{inputs.parameters.segment_length}}"

          - name: split-filename
            template: split-filename
            arguments:
              parameters:
                - name: gds_file
                  value: "{{=map(jsonpath(inputs.parameters.gds_files, '$'), {#})[0]}}"

          - name: filter-segments
            template: filter-segments
            dependencies: [define-segments, split-filename]
            arguments:
              parameters:
                - name: file_prefix
                  value: "{{=jsonpath(tasks['split-filename'].outputs.result, '$.file_prefix')}}"
                - name: file_suffix
                  value: "{{=jsonpath(tasks['split-filename'].outputs.result, '$.file_suffix')}}"
                - name: gds_filenames
                  value: "{{inputs.parameters.gds_files}}"
              artifacts:
                - name: segment_file
                  from: "{{tasks.define-segments.outputs.artifacts.segment_file}}"

          - name: run-single-assoc
            template: run-single-assoc
            dependencies: [run-null-model, filter-segments, split-filename, run-impute-score-filter]
            arguments:
              parameters:
                - name: file_prefix
                  value: "{{=jsonpath(tasks['split-filename'].outputs.result, '$.file_prefix')}}"
                - name: file_suffix
                  value: "{{=jsonpath(tasks['split-filename'].outputs.result, '$.file_suffix')}}"
                - name: gds_files
                  value: "{{inputs.parameters.gds_files}}"
                - name: genome_build
                  value: "{{inputs.parameters.genome_build}}"
                - name: out_prefix
                  value: "{{inputs.parameters.out_prefix}}"
                - name: variant_block_size
                  value: "{{inputs.parameters.variant_block_size}}"
                - name: outcome_is_binary
                  value: "{{inputs.parameters.outcome_is_binary}}"
                - name: mac_threshold
                  value: "{{inputs.parameters.mac_threshold}}"
                - name: maf_threshold
                  value: "{{inputs.parameters.maf_threshold}}"
                - name: segment
                  value: "{{item}}"
              artifacts:
                - name: segment_file
                  from: "{{tasks.define-segments.outputs.artifacts.segment_file}}"
                - name: phenotype_file
                  from: "{{tasks.run-null-model.outputs.artifacts.null_model_phenotype}}"
                - name: null_model_results
                  from: "{{tasks.run-null-model.outputs.artifacts.null_model_directory}}"
                - name: variant_list_dir
                  s3:
                    key: "{{workflow.name}}/variant_lists"
            withParam: "{{=toJson(jsonpath(tasks['filter-segments'].outputs.result, '$.segments'))}}"

          - name: combine-shards
            template: combine-shards
            dependencies: [run-single-assoc]
            arguments:
              parameters:
                - name: chromosome
                  value: "{{item}}"
                - name: out_prefix
                  value: "{{inputs.parameters.out_prefix}}"
              artifacts:
                - name: file_shards
                  s3:
                    key: "{{workflow.name}}/single_assoc_chunks"
            withParam: "{{=toJson(jsonpath(tasks['filter-segments'].outputs.result, '$.chromosomes'))}}"

          - name: run-plots
            template: run-plots
            dependencies: [combine-shards]
            arguments:
              parameters:
                - name: chromosomes
                  value: "{{=sprig.join(' ', jsonpath(tasks['filter-segments'].outputs.result, '$.chromosomes'))}}"
                - name: out_prefix
                  value: "{{inputs.parameters.out_prefix}}"
              artifacts:
                - name: combined
                  s3:
                    key: "{{workflow.name}}/single_assoc_combined"

          - name: annotate-statistics
            template: run-annotate
            dependencies: [combine-shards]
            arguments:
              parameters:
                - name: chromosome
                  value: "{{item}}"
                - name: out_prefix
                  value: "{{inputs.parameters.out_prefix}}"
              artifacts:
                - name: raw_stats
                  s3:
                    key: "{{workflow.name}}/single_assoc_combined/{{inputs.parameters.out_prefix}}_chr{{item}}.RData"
            withParam: "{{=toJson(jsonpath(tasks['filter-segments'].outputs.result, '$.chromosomes'))}}"

          - name: archive-outputs
            template: run-tar
            dependencies: [run-plots, annotate-statistics]
            arguments:
              parameters:
                - name: out_prefix
                  value: "{{inputs.parameters.out_prefix}}"
              artifacts:
                - name: manhattan_plot
                  from: "{{tasks.run-plots.outputs.artifacts.manhattan_plot}}"
                - name: qq_plot 
                  from: "{{tasks.run-plots.outputs.artifacts.qq_plot}}"
                - name: annotated_csvs
                  s3:
                    key: "{{workflow.name}}/annotated_csvs"

          - name: generate-indexd-meta
            template: gen-indexd-meta
            dependencies: [archive-outputs]
            arguments:
              parameters:
                - name: arborist_resource
                  value: "/cohort-middleware"
              artifacts:
                - name: gwas_archive
                  from: "{{tasks.archive-outputs.outputs.artifacts.gwas_archive}}"

          - name: create-indexd-record
            template: gen-indexd-record
            dependencies: [generate-indexd-meta]
            arguments:
              artifacts:
                - name: request_data
                  from: "{{tasks.generate-indexd-meta.outputs.artifacts.indexd_record}}"

    - name: get-cohort-middleware-csv
      inputs:
        parameters:
          - name: cohort_middleware_url
          - name: cohort_middleware_body
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"
      script:
        image: alpine/curl:3.14
        imagePullPolicy: IfNotPresent
        command: [sh]
        source: |
          apk add --no-cache jq
          TOKEN=$(curl --silent http://workspace-token-service.default/token/?idp=default | jq .token -r)
          curl \
          --header "Authorization: bearer ${TOKEN}" \
          --header "Content-Type: application/json" \
          --request POST \
          --data '{{inputs.parameters.cohort_middleware_body}}' \
          {{inputs.parameters.cohort_middleware_url}} > /mnt/vol/pheno.csv
        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
      outputs:
        artifacts:
          - name: pheno_csv
            path: /mnt/vol/pheno.csv
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/{{pod.name}}/pheno.csv"

    - name: generate-pheno
      inputs:
        artifacts:
          - name: pheno_csv
            mode: 0777
            path: "/mnt/vol/phenotypes.csv"
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"
      script:
        image: quay.io/cdis/topmed-master:2.12.0
        imagePullPolicy: IfNotPresent
        command: [Rscript]
        source: |
          library(Biobase)

          dat.csv <- read.csv("{{inputs.artifacts.pheno_csv.path}}", stringsAsFactors=FALSE, na.strings=c("NA", ""))
          dat.csv$sample.id <- as.character(dat.csv$sample.id)
          annot <- AnnotatedDataFrame(dat.csv)
          stopifnot("sample.id" %in% varLabels(annot))
          save(annot, file="/mnt/vol/phenotypes.Rdata")

        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
        resources:
          requests:
            cpu: 500m
            memory: 512Mi
      outputs:
        artifacts:
          - name: phenotype_file
            path: "/mnt/vol/phenotypes.Rdata"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/{{pod.name}}/phenotypes.Rdata"

    - name: impute-score-filter
      inputs:
        parameters:
          - name: impute_cutoff
          - name: gds_file
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"
      script:
        image: quay.io/cdis/topmed-master:2.12.0
        imagePullPolicy: IfNotPresent
        command: [Rscript]
        source: |
          library(SeqVarTools)

          gdsFile <- "{{inputs.parameters.gds_file}}"
          imputation.cutoff <- {{inputs.parameters.impute_cutoff}}
          chrom <- gsub("(.*)(chr[0-9X]+)(.*)", "\\2", basename(gdsFile))
          cat("gds:", gdsFile, "chromosome:", chrom, "\n")

          dir.create("/mnt/vol/variant_lists")
          outFile <- file.path("/mnt/vol/variant_lists", paste0(chrom, ".selected_variants.RData"))

          gds <- seqOpen(gdsFile)

          all.variant.ids <- seqGetData(gds, "variant.id")
          imputation.fit <- seqGetData(gds, "annotation/info/R2")
          sel <- imputation.fit >= imputation.cutoff | is.na(imputation.fit)
          variant.ids <- all.variant.ids[sel]
          save(variant.ids, file=outFile)
          seqClose(gds)
          
          cat("Total variants:", length(all.variant.ids),
              "\nDropped variants:", length(all.variant.ids) - length(variant.ids),
              "\nRemaining variants (%):", length(variant.ids),
                  paste0("(", round(100*(length(variant.ids)/length(all.variant.ids)), 2), "%)"), "\n")

        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
          - name: gateway
            mountPath: /commons-data
        resources:
          requests:
            cpu: 500m
            memory: 512Mi
      outputs:
        artifacts:
          - name: variant_list_dir
            path: "/mnt/vol/variant_lists"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/variant_lists"


    - name: run-null-model
      inputs:
        parameters:
          - name: n_pcs
          - name: covariates
          - name: out_prefix
          - name: outcome
          - name: outcome_is_binary
          - name: pca_file
          - name: relatedness_matrix_file
        artifacts:
          - name: phenotype_file
            mode: 0777
            path: "/mnt/vol/phenotypes.Rdata"
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"

      script:
        image: quay.io/cdis/topmed-master:2.12.0
        imagePullPolicy: IfNotPresent
        command: [bash]
        source: |
          export NSLOTS=2
          cd /mnt/vol


          echo "out_prefix {{inputs.parameters.out_prefix}}" > null_model.config
          echo "phenotype_file {{inputs.artifacts.phenotype_file.path}}" >> null_model.config
          echo "outcome {{inputs.parameters.outcome}}" >> null_model.config
          if [[ "{{inputs.parameters.outcome_is_binary}}" == "TRUE" ]]; then
                echo "family \"binomial\"" >> null_model.config
          else
                echo "family \"gaussian\"" >> null_model.config
          fi
          echo "n_pcs {{inputs.parameters.n_pcs}}" >> null_model.config
          echo "pca_file {{inputs.parameters.pca_file}}" >> null_model.config
          echo "relatedness_matrix_file {{inputs.parameters.relatedness_matrix_file}}" >> null_model.config
          echo "covars \"{{inputs.parameters.covariates}}\"" >> null_model.config
          echo "out_phenotype_file {{inputs.parameters.out_prefix}}_phenotypes.Rdata" >> null_model.config

          set -xe
          cat null_model.config

          Rscript /usr/local/analysis_pipeline/R/null_model.R null_model.config
          Rscript /usr/local/analysis_pipeline/R/null_model_report.R null_model.config --version 2.12.0
          ls -al

          DATADIR={{inputs.parameters.out_prefix}}_datadir
          mkdir $DATADIR
          mv {{inputs.parameters.out_prefix}}*.RData $DATADIR/

          REPORTDIR={{inputs.parameters.out_prefix}}_reports
          mkdir $REPORTDIR
          mv *.html $REPORTDIR/
          mv *.Rmd $REPORTDIR/

        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
          - name: gateway
            mountPath: /commons-data

        resources:
          requests:
            cpu: 2500m
            memory: 2Gi

      outputs:
        artifacts:
          - name: null_model_directory
            path: "/mnt/vol/{{inputs.parameters.out_prefix}}_datadir"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/{{pod.name}}/{{inputs.parameters.out_prefix}}_datadir"
          - name: null_model_phenotype
            path: "/mnt/vol/{{inputs.parameters.out_prefix}}_phenotypes.Rdata"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/{{pod.name}}/{{inputs.parameters.out_prefix}}_phenotypes.Rdata"
          - name: null_model_report_directory
            path: "/mnt/vol/{{inputs.parameters.out_prefix}}_reports"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/{{pod.name}}/{{inputs.parameters.out_prefix}}_reports"

    - name: define-segments
      inputs:
        parameters:
          - name: genome_build
          - name: n_segments
          - name: segment_length
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"

      script:
        image: quay.io/cdis/topmed-master:2.12.0
        imagePullPolicy: IfNotPresent
        command: [bash]
        source: |
          cd /mnt/vol
          echo "genome_build {{inputs.parameters.genome_build}}" > define_segments.config
          echo "out_file segments.txt" >> define_segments.config

          if [[ "{{inputs.parameters.n_segments}}" == "0" ]]; then
              NSEG=""
          else
              NSEG=" --n_segments {{inputs.parameters.n_segments}}"
          fi

          Rscript /usr/local/analysis_pipeline/R/define_segments.R \
          define_segments.config \
          --segment_length {{inputs.parameters.segment_length}}${NSEG}

        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol

        resources:
          requests:
            cpu: 256m
            memory: 512Mi

      outputs:
        artifacts:
          - name: segment_file
            path: "/mnt/vol/segments.txt"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/{{pod.name}}/segments.txt"

    - name: split-filename
      inputs:
        parameters:
          - name: gds_file
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"

      script:
        image: python:3.7
        imagePullPolicy: IfNotPresent
        command: [python3]
        source: |
          import json
          import os
          import sys

          gds_file = "{{inputs.parameters.gds_file}}"
          bname = os.path.basename(gds_file)
          pfx = bname.split("chr")[0] + 'chr'
          sfx = "." + ".".join(bname.split("chr")[1].split(".")[1:])
          dat = {"file_prefix": pfx, "file_suffix": sfx}
          json.dump(dat, sys.stdout)

        resources:
          requests:
            cpu: 50m
            memory: 50Mi

    - name: filter-segments
      inputs:
        parameters:
          - name: gds_filenames
          - name: file_prefix
          - name: file_suffix
        artifacts:
          - name: segment_file
            path: "/mnt/vol/segments.txt"
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"

      script:
        image: python:3.7
        imagePullPolicy: IfNotPresent
        command: [python3]
        source: |
          import json
          import os
          import sys

          gds_files = set([os.path.basename(i) for i in {{inputs.parameters.gds_filenames}}])
          file_prefix = "{{inputs.parameters.file_prefix}}"
          file_suffix = "{{inputs.parameters.file_suffix}}"
          segments_file = "{{inputs.artifacts.segment_file.path}}"

          chromosomes_present = set()
          segments = []
          with open(segments_file, "rt") as f:
              for n, line in enumerate(f.readlines()):
                  chrom = line.split()[0]
                  if file_prefix + chrom + file_suffix in gds_files:
                      chromosomes_present.add(chrom)
                      segments += [n]

          dat = {
            "chromosomes": list(chromosomes_present),
            "segments": segments
          }
          json.dump(dat, sys.stdout)

        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
        resources:
          requests:
            cpu: 50m
            memory: 50Mi

    - name: run-single-assoc
      inputs:
        parameters:
          - name: gds_files
          - name: out_prefix
          - name: genome_build
          - name: file_prefix
          - name: file_suffix
          - name: segment
          - name: variant_block_size
          - name: mac_threshold
          - name: maf_threshold
          - name: outcome_is_binary
        artifacts:
          - name: segment_file
            mode: 0777
            path: "/mnt/vol/segments.txt"
          - name: null_model_results
            mode: 0777
            path: "/mnt/vol/null_model_results"
          - name: phenotype_file
            mode: 0777
            path: "/mnt/vol/phenotypes.RData"
          - name: variant_list_dir
            mode: 0777
            path: "/mnt/vol/variant_lists"
      retryStrategy:
        limit: "5"
        retryPolicy: "Always"

      script:
        image: quay.io/cdis/topmed-master:2.12.0
        imagePullPolicy: IfNotPresent
        securityContext:
          runAsUser: 0
        command: [bash]
        source: |
          cd /mnt/vol
          for fil in {{=sprig.join(" ", map(jsonpath(inputs.parameters.gds_files, '$'), {#}))}}; do
              ln -s $fil .
          done

          set -xe
          CHROM="$(awk 'NR=={{=asInt(inputs.parameters.segment) + 1}} {print $1}' {{inputs.artifacts.segment_file.path}})" 
          echo $CHROM

          echo "out_prefix {{inputs.parameters.out_prefix}}" > assoc_single.config
          echo "genome_build {{inputs.parameters.genome_build}}" >> assoc_single.config
          echo "gds_file \"{{inputs.parameters.file_prefix}} {{inputs.parameters.file_suffix}}\"" >> assoc_single.config
          echo "phenotype_file {{inputs.artifacts.phenotype_file.path}}" >> assoc_single.config
          echo "segment_file {{inputs.artifacts.segment_file.path}}" >> assoc_single.config
          echo "variant_block_size {{inputs.parameters.variant_block_size}}" >> assoc_single.config
          echo "variant_include_file {{inputs.artifacts.variant_list_dir.path}}/chr${CHROM}.selected_variants.RData" >> assoc_single.config
          if [[ "{{inputs.parameters.outcome_is_binary}}" == "TRUE" ]]; then
                echo "null_model_file {{inputs.artifacts.null_model_results.path}}/{{inputs.parameters.out_prefix}}_null_model.RData" >> assoc_single.config
                echo "test_type \"score.spa\"" >> null_model.config
          else
                echo "null_model_file {{inputs.artifacts.null_model_results.path}}/{{inputs.parameters.out_prefix}}_null_model_invnorm.RData" >> assoc_single.config
          fi

          if [[ "{{inputs.parameters.mac_threshold}}" == "0" ]]; then
              echo "mac_threshold NA" >> assoc_single.config
              echo "maf_threshold {{inputs.parameters.maf_threshold}}" >> assoc_single.config
          else
              echo "mac_threshold {{inputs.parameters.mac_threshold}}" >> assoc_single.config
          fi

          cat assoc_single.config
          ls -al

          Rscript /usr/local/analysis_pipeline/R/assoc_single.R assoc_single.config --chromosome $CHROM \
          --segment {{inputs.parameters.segment}} \
          --num_cores 1

          SEGOUT="{{inputs.parameters.out_prefix}}_chr${CHROM}_seg{{inputs.parameters.segment}}.RData"
          mkdir single_assoc_chunks

          if [[ -f $SEGOUT ]]; then
                mv $SEGOUT single_assoc_chunks/
          else
                echo "No outputs for segment... skipping..."
          fi

        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
          - name: gateway
            mountPath: /commons-data

        resources:
          requests:
            cpu: 2000m
            memory: 12Gi
      outputs:
        artifacts:
          - name: single_assoc_segment_output
            path: "/mnt/vol/single_assoc_chunks"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/single_assoc_chunks"

    - name: combine-shards
      inputs:
        parameters:
          - name: chromosome
          - name: out_prefix
        artifacts:
          - name: file_shards
            mode: 0777
            path: "/mnt/vol/file_shards"
      retryStrategy:
        limit: "4"
        retryPolicy: "Always"

      script:
        image: quay.io/cdis/topmed-master:2.12.0
        imagePullPolicy: IfNotPresent
        securityContext:
          runAsUser: 0
        command: [bash]
        source: |
          cd {{inputs.artifacts.file_shards.path}}

          echo "out_prefix {{inputs.parameters.out_prefix}}" > assoc_combine.config
          echo "assoc_type \"single\"" >> assoc_combine.config

          cat assoc_combine.config
          ls -al

          set -xe
          Rscript /usr/local/analysis_pipeline/R/assoc_combine.R \
          assoc_combine.config \
          --chromosome {{inputs.parameters.chromosome}}
          mkdir single_assoc_combined
          mv {{inputs.parameters.out_prefix}}_chr{{inputs.parameters.chromosome}}.RData single_assoc_combined/

        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
        resources:
          requests:
            cpu: 1000m
            memory: 2000Mi
      outputs:
        artifacts:
          - name: single_assoc_combined
            path: "{{inputs.artifacts.file_shards.path}}/single_assoc_combined"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/single_assoc_combined"

    - name: run-plots
      inputs:
        parameters:
          - name: chromosomes
          - name: out_prefix
        artifacts:
          - name: combined
            mode: 0777
            path: "/mnt/vol/combined"
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"

      script:
        image: quay.io/cdis/topmed-master:2.12.0
        imagePullPolicy: IfNotPresent
        securityContext:
          runAsUser: 0
        command: [bash]
        source: |
          cd {{inputs.artifacts.combined.path}}

          echo "assoc_type \"single\"" > plots.config
          echo "thin \"TRUE\"" >> plots.config
          echo "assoc_file \"{{inputs.parameters.out_prefix}}_chr .RData\"" >> plots.config
          echo "chromosomes \"{{inputs.parameters.chromosomes}}\"" >> plots.config
          echo "out_file_manh \"{{inputs.parameters.out_prefix}}_manhattan.png\"" >> plots.config
          echo "out_file_qq \"{{inputs.parameters.out_prefix}}_qq.png\"" >> plots.config

          cat plots.config
          ls -al

          set -xe
          Rscript /usr/local/analysis_pipeline/R/assoc_plots.R plots.config

        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
        resources:
          requests:
            cpu: 256m
            memory: 1000Mi
      outputs:
        artifacts:
          - name: manhattan_plot
            path: "{{inputs.artifacts.combined.path}}/{{inputs.parameters.out_prefix}}_manhattan.png"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/gwas_plots/{{inputs.parameters.out_prefix}}_manhattan.png"
          - name: qq_plot
            path: "{{inputs.artifacts.combined.path}}/{{inputs.parameters.out_prefix}}_qq.png"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/gwas_plots/{{inputs.parameters.out_prefix}}_qq.png"

    - name: run-annotate
      inputs:
        parameters:
          - name: chromosome
          - name: out_prefix
        artifacts:
          - name: raw_stats
            mode: 0777
            path: "/mnt/vol/raw_stats.RData"
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"

      script:
        image: quay.io/cdis/topmed-master:2.12.0
        imagePullPolicy: IfNotPresent
        securityContext:
          runAsUser: 0
        command: [Rscript]
        source: |
          library(dplyr)

          # Load summary stats
          load("{{inputs.artifacts.raw_stats.path}}")

          # Load RSID meta
          anno.df <- read.delim("/commons-data/kmhernan/marker_metadata/vadc_mvp_marker_annotation.chr{{inputs.parameters.chromosome}}.rsids.tsv.gz",
                                header=TRUE,
                                stringsAsFactors=FALSE,
                                sep="\t")

          # Load var meta
          varmeta.df <- read.csv("/commons-data/kmhernan/marker_metadata/vadc_mvp_marker_annotation.chr{{inputs.parameters.chromosome}}.var_meta.csv.gz",
                                 stringsAsFactors=FALSE) %>%
            mutate(chr=as.character(chr))

          # Make annotated df
          annotated.summary.df <- varmeta.df %>%
            left_join(anno.df, by=c("variant.name"="variant.name")) %>%
            inner_join(assoc, by=c("variant.id"="variant.id", "chr"="chr", "pos"="pos")) %>%
            mutate(chr=paste0("chr", chr))

          # Write new CSV
          write.csv(annotated.summary.df,
            file=gzfile("/mnt/vol/{{inputs.parameters.out_prefix}}_chr{{inputs.parameters.chromosome}}.annotated_summary.csv.gz"),
            row.names=FALSE,
            na="")

        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
          - name: gateway
            mountPath: /commons-data
        resources:
          requests:
            cpu: 256m
            memory: 1000Mi
      outputs:
        artifacts:
          - name: annotated_stats_csv
            path: "/mnt/vol/{{inputs.parameters.out_prefix}}_chr{{inputs.parameters.chromosome}}.annotated_summary.csv.gz"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/annotated_csvs/{{inputs.parameters.out_prefix}}_chr{{inputs.parameters.chromosome}}.annotated_summary.csv.gz"

    - name: run-tar
      inputs:
        parameters:
          - name: out_prefix
        artifacts:
          - name: manhattan_plot
            path: "/mnt/vol/{{workflow.name}}/{{inputs.parameters.out_prefix}}_manhattan.png"
          - name: qq_plot 
            path: "/mnt/vol/{{workflow.name}}/{{inputs.parameters.out_prefix}}_qq.png"
          - name: annotated_csvs
            mode: 0777
            path: "/mnt/vol/{{workflow.name}}/annotated_summary_csvs"
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"

      script:
        image: alpine:latest
        imagePullPolicy: IfNotPresent
        command: [/bin/sh]
        source: |
          cd /mnt/vol
          tar -czf {{workflow.name}}.tar.gz {{workflow.name}}/

        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
        resources:
          requests:
            cpu: 256m
            memory: 500Mi

      outputs:
        artifacts:
          - name: gwas_archive
            path: "/mnt/vol/{{workflow.name}}.tar.gz"
            archive:
              none: {}
            s3:
              endpoint: s3.amazonaws.com
              bucket: argo-artifact-storage-downloadable 
              key: "{{workflow.name}}/{{workflow.name}}.tar.gz"
              accessKeySecret:
                name: argo-s3-creds
                key: AccessKeyId
              secretKeySecret:
                name: argo-s3-creds
                key: SecretAccessKey

    - name: gen-indexd-meta
      inputs:
        parameters:
          - name: arborist_resource
        artifacts:
          - name: gwas_archive
            path: /mnt/vol/archive.tar.gz
      script:
        image: python:3.7
        imagePullPolicy: IfNotPresent
        command: [python3]
        source: |
          import json
          import hashlib
          import os

          def get_md5_sum(fil):
              md5 = hashlib.md5()
              with open(fil, 'rb') as fh:
                  while True:
                      r = fh.read(8192)
                      if not r:
                          break
                      md5.update(r)
              return {"md5": str(md5.hexdigest())}

          if __name__ == '__main__':
              hash_meta = get_md5_sum("{{inputs.artifacts.gwas_archive.path}}")
              fsize = int(os.stat("{{inputs.artifacts.gwas_archive.path}}").st_size)
              data = {
                "authz": ["{{inputs.parameters.arborist_resource}}"],
                "file_name": "{{workflow.name}}.tar.gz",
                "hashes": hash_meta,
                "size": fsize,
                "urls": ["s3://argo-artifact-storage-downloadable/{{workflow.name}}/{{workflow.name}}.tar.gz"],
                "urls_metadata": {
                        "s3://argo-artifact-storage-downloadable/{{workflow.name}}/{{workflow.name}}.tar.gz": {}
                },
                "form": "object"
              }
              with open("/mnt/vol/record.json", 'wt') as o:
                  json.dump(data, o)
        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
      outputs:
        artifacts:
          - name: indexd_record
            path: "/mnt/vol/record.json" 
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/{{pod.name}}/indexd_record.json"

    - name: gen-indexd-record
      inputs:
        artifacts:
          - name: request_data
            path: /mnt/vol/request.json
      script:
        image: alpine/curl:3.14
        imagePullPolicy: IfNotPresent
        command: [sh]
        source: |
          AUTH=$(echo -ne "$INDEXDUSER:$INDEXDPASS" | base64 -w 0)
          curl \
          --header "Content-Type: application/json" \
          --header "Authorization: Basic $AUTH" \
          --request POST --data "@/mnt/vol/request.json" http://indexd-service.default/index > /mnt/vol/did.json
        env:
          - name: INDEXDUSER
            valueFrom:
              secretKeyRef:
                name: indexd-creds
                key: user
          - name: INDEXDPASS
            valueFrom:
              secretKeyRef:
                name: indexd-creds
                key: password
        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
      outputs:
        parameters:
          - name: gwas_archive_index
            valueFrom:
              path: /mnt/vol/did.json
            globalName: gwas_archive_index
