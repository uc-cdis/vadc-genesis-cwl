apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: gwas-template
spec:
  entrypoint: gwas-workflow

  templates:
    - name: gwas-workflow
      inputs:
        parameters:
          - name: internal_api_env
            default: default
          - name: source_id
          - name: case_cohort_definition_id
          - name: control_cohort_definition_id
            default: -1
          - name: prefixed_hare_concept_id
            default: ID_2000007027
          - name: hare_population
          - name: n_pcs
            default: 0
          - name: covariates
          - name: out_prefix
            value: vadc_genesis
          - name: outcome
            default: -1
          - name: pca_file
          - name: relatedness_matrix_file
          - name: genome_build
            enum:
              - "hg38"
              - "hg19"
            default: "hg19"
          - name: n_segments
            default: 0
          - name: segment_length
            default: 10000
          - name: variant_block_size
            default: 1024
          - name: mac_threshold
          - name: maf_threshold
            default: 0.01
          - name: imputation_score_cutoff
            default: 0.03
          - name: gds_files

      dag:
        tasks:
          - name: get-pheno-csv-flow
            template: get-pheno-dag
            arguments:
              parameters:
                - name: source_id
                  value: "{{inputs.parameters.source_id}}"
                - name: case_cohort_definition_id
                  value: "{{inputs.parameters.case_cohort_definition_id}}"
                - name: control_cohort_definition_id
                  value: "{{inputs.parameters.control_cohort_definition_id}}"
                - name: prefixed_hare_concept_id 
                  value: "{{inputs.parameters.prefixed_hare_concept_id}}"
                - name: outcome
                  value: "{{inputs.parameters.outcome}}"
                - name: covariates
                  value: "{{inputs.parameters.covariates}}"
                - name: internal_api_env
                  value: "{{inputs.parameters.internal_api_env}}"

          - name: generate-pheno
            template: generate-pheno
            dependencies: [get-pheno-csv-flow]
            arguments:
              parameters:
                - name: prefixed_hare_concept_id
                  from: "{{inputs.parameters.prefixed_hare_concept_id}}"
                - name: hare_population 
                  from: "{{inputs.parameters.hare_population}}"
              artifacts:
                - name: pheno_csv
                  from: "{{tasks.get-pheno-csv-flow.outputs.artifacts.pheno_csv}}"

          - name: run-impute-score-filter
            template: impute-score-filter
            dependencies: [generate-pheno]
            arguments:
              parameters:
                - name: impute_cutoff
                  value: "{{inputs.parameters.imputation_score_cutoff}}"
                - name: gds_file
                  value: "{{item}}"
            withParam: "{{=toJson(map(jsonpath(inputs.parameters.gds_files, '$'), {#}))}}"

          - name: run-null-model
            template: run-null-model
            dependencies: [generate-pheno]
            arguments:
              parameters:
                - name: n_pcs
                  value: "{{inputs.parameters.n_pcs}}"
                - name: covariates
                  value: "{{inputs.parameters.covariates}}"
                - name: out_prefix
                  value: "{{inputs.parameters.out_prefix}}_null_model"
                - name: outcome
                  value: "{{= inputs.parameters.control_cohort_definition_id == '-1' ? inputs.parameters.outcome : 'CASE_CONTROL' }}"
                - name: outcome_is_binary
                  value: "{{= inputs.parameters.control_cohort_definition_id == '-1' ? 'FALSE' : 'TRUE' }}"
                - name: pca_file
                  value: "{{inputs.parameters.pca_file}}"
                - name: relatedness_matrix_file
                  value: "{{inputs.parameters.relatedness_matrix_file}}"
              artifacts:
                - name: phenotype_file
                  from: "{{tasks.generate-pheno.outputs.artifacts.phenotype_file}}"

          - name: define-segments
            template: define-segments
            arguments:
              parameters:
                - name: genome_build
                  value: "{{inputs.parameters.genome_build}}"
                - name: n_segments
                  value: "{{inputs.parameters.n_segments}}"
                - name: segment_length
                  value: "{{inputs.parameters.segment_length}}"

          - name: split-filename
            template: split-filename
            arguments:
              parameters:
                - name: gds_file
                  value: "{{=map(jsonpath(inputs.parameters.gds_files, '$'), {#})[0]}}"

          - name: filter-segments
            template: filter-segments
            dependencies: [define-segments, split-filename]
            arguments:
              parameters:
                - name: file_prefix
                  value: "{{=jsonpath(tasks['split-filename'].outputs.result, '$.file_prefix')}}"
                - name: file_suffix
                  value: "{{=jsonpath(tasks['split-filename'].outputs.result, '$.file_suffix')}}"
                - name: gds_filenames
                  value: "{{inputs.parameters.gds_files}}"
              artifacts:
                - name: segment_file
                  from: "{{tasks.define-segments.outputs.artifacts.segment_file}}"

          - name: run-single-assoc
            template: run-single-assoc
            dependencies: [run-null-model, filter-segments, split-filename, run-impute-score-filter]
            arguments:
              parameters:
                - name: file_prefix
                  value: "{{=jsonpath(tasks['split-filename'].outputs.result, '$.file_prefix')}}"
                - name: file_suffix
                  value: "{{=jsonpath(tasks['split-filename'].outputs.result, '$.file_suffix')}}"
                - name: gds_files
                  value: "{{inputs.parameters.gds_files}}"
                - name: genome_build
                  value: "{{inputs.parameters.genome_build}}"
                - name: out_prefix
                  value: "{{inputs.parameters.out_prefix}}"
                - name: variant_block_size
                  value: "{{inputs.parameters.variant_block_size}}"
                - name: outcome_is_binary
                  value: "{{= inputs.parameters.control_cohort_definition_id == '-1' ? 'FALSE' : 'TRUE' }}"
                - name: mac_threshold
                  value: "{{inputs.parameters.mac_threshold}}"
                - name: maf_threshold
                  value: "{{inputs.parameters.maf_threshold}}"
                - name: segment
                  value: "{{item}}"
              artifacts:
                - name: segment_file
                  from: "{{tasks.define-segments.outputs.artifacts.segment_file}}"
                - name: phenotype_file
                  from: "{{tasks.run-null-model.outputs.artifacts.null_model_phenotype}}"
                - name: null_model_results
                  from: "{{tasks.run-null-model.outputs.artifacts.null_model_directory}}"
                - name: variant_list_dir
                  s3:
                    key: "{{workflow.name}}/variant_lists"
            withParam: "{{=toJson(jsonpath(tasks['filter-segments'].outputs.result, '$.segments'))}}"

          - name: combine-shards
            template: combine-shards
            dependencies: [run-single-assoc]
            arguments:
              parameters:
                - name: chromosome
                  value: "{{item}}"
                - name: out_prefix
                  value: "{{inputs.parameters.out_prefix}}"
              artifacts:
                - name: file_shards
                  s3:
                    key: "{{workflow.name}}/single_assoc_chunks"
            withParam: "{{=toJson(jsonpath(tasks['filter-segments'].outputs.result, '$.chromosomes'))}}"

          - name: run-plots
            template: run-plots
            dependencies: [combine-shards]
            arguments:
              parameters:
                - name: chromosomes
                  value: "{{=sprig.join(' ', jsonpath(tasks['filter-segments'].outputs.result, '$.chromosomes'))}}"
                - name: out_prefix
                  value: "{{inputs.parameters.out_prefix}}"
              artifacts:
                - name: combined
                  s3:
                    key: "{{workflow.name}}/single_assoc_combined"

          - name: annotate-statistics
            template: run-annotate
            dependencies: [combine-shards]
            arguments:
              parameters:
                - name: chromosome
                  value: "{{item}}"
                - name: out_prefix
                  value: "{{inputs.parameters.out_prefix}}"
              artifacts:
                - name: raw_stats
                  s3:
                    key: "{{workflow.name}}/single_assoc_combined/{{inputs.parameters.out_prefix}}_chr{{item}}.RData"
            withParam: "{{=toJson(jsonpath(tasks['filter-segments'].outputs.result, '$.chromosomes'))}}"

          - name: generate-gwas-metadata
            template: get-gwas-metadata
            arguments:
              parameters:
                - name: source_id
                  value: "{{inputs.parameters.source_id}}"
                - name: case_cohort_id
                  value: "{{inputs.parameters.case_cohort_definition_id}}"
                - name: control_cohort_id
                  value: "{{inputs.parameters.control_cohort_definition_id}}"
                - name: prefixed_outcome_concept_id
                  value: "{{inputs.parameters.outcome}}"
                - name: prefixed_concept_ids
                  value: "{{inputs.parameters.covariates}}"
                - name: internal_api_env
                  value: "{{inputs.parameters.internal_api_env}}"
                - name: n_pcs
                  value: "{{inputs.parameters.n_pcs}}"
                - name: maf_threshold
                  value: "{{inputs.parameters.maf_threshold}}"
                - name: imputation_score_cutoff
                  value: "{{inputs.parameters.imputation_score_cutoff}}"
                - name: hare_population
                  value: "{{inputs.parameters.hare_population}}"

          - name: archive-outputs
            template: run-tar
            dependencies: [run-plots, annotate-statistics, generate-gwas-metadata]
            arguments:
              parameters:
                - name: out_prefix
                  value: "{{inputs.parameters.out_prefix}}"
              artifacts:
                - name: manhattan_plot
                  from: "{{tasks.run-plots.outputs.artifacts.manhattan_plot}}"
                - name: qq_plot 
                  from: "{{tasks.run-plots.outputs.artifacts.qq_plot}}"
                - name: annotated_csvs
                  s3:
                    key: "{{workflow.name}}/annotated_csvs"
                - name: gwas_metadata
                  from: "{{tasks.generate-gwas-metadata.outputs.artifacts.gwas_metadata}}"

          - name: generate-indexd-meta
            template: gen-indexd-meta
            dependencies: [archive-outputs]
            arguments:
              parameters:
                - name: arborist_resource
                  value: "/cohort-middleware"
              artifacts:
                - name: gwas_archive
                  from: "{{tasks.archive-outputs.outputs.artifacts.gwas_archive}}"

          - name: create-indexd-record
            template: gen-indexd-record
            dependencies: [generate-indexd-meta]
            arguments:
              artifacts:
                - name: request_data
                  from: "{{tasks.generate-indexd-meta.outputs.artifacts.indexd_record}}"

    - name: get-pheno-dag
      inputs:
        parameters:
          - name: internal_api_env
          - name: source_id
          - name: case_cohort_definition_id
          - name: control_cohort_definition_id
          - name: prefixed_hare_concept_id
          - name: outcome
          - name: covariates
      dag:
        tasks:
          - name: get-quantitative-pheno-csv
            template: get-cohort-middleware-csv-continuous
            arguments:
              parameters:
                - name: source_id
                  value: "{{inputs.parameters.source_id}}"
                - name: case_cohort_id
                  value: "{{inputs.parameters.case_cohort_definition_id}}"
                - name: prefixed_concept_ids
                  value: "{{inputs.parameters.outcome}} {{inputs.parameters.covariates}} {{inputs.parameters.prefixed_hare_concept_id}}"
                - name: gen3environment
                  value: "{{inputs.parameters.internal_api_env}}"
            when: "{{inputs.parameters.control_cohort_definition_id}} == -1"

          - name: get-case-control-pheno-csv
            template: get-cohort-middleware-csv-case-control
            arguments:
              parameters:
                - name: source_id
                  value: "{{inputs.parameters.source_id}}"
                - name: case_cohort_id
                  value: "{{inputs.parameters.case_cohort_definition_id}}"
                - name: control_cohort_id
                  value: "{{inputs.parameters.control_cohort_definition_id}}"
                - name: prefixed_concept_ids
                  value: "{{inputs.parameters.covariates}} {{inputs.parameters.prefixed_hare_concept_id}}"
                - name: gen3environment
                  value: "{{inputs.parameters.internal_api_env}}"
            when: "{{inputs.parameters.control_cohort_definition_id}} != -1"
      outputs:
        artifacts:
          - name: pheno_csv
            fromExpression: "inputs.parameters.control_cohort_definition_id == '-1' ? tasks['get-quantitative-pheno-csv'].outputs.artifacts.pheno_csv : tasks['get-case-control-pheno-csv'].outputs.artifacts.pheno_csv"

    - name: get-cohort-middleware-csv-continuous
      inputs:
        parameters:
          - name: source_id
          - name: case_cohort_id
          - name: prefixed_concept_ids
          - name: gen3environment
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"
      container:
        image: quay.io/cdis/vadc-gwas-tools:master
        imagePullPolicy: Always
        command: ["/bin/bash", "-c"]
        args: ["/env/bin/vadc-gwas-tools GetCohortPheno --source_id {{inputs.parameters.source_id}} \
          --case_cohort_id {{inputs.parameters.case_cohort_id}} \
          -o /mnt/vol/pheno.csv.gz \
          --prefixed_concept_ids {{inputs.parameters.prefixed_concept_ids}}
        "]
        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
        env:
          - name: GEN3_ENVIRONMENT
            value: "{{inputs.parameters.gen3environment}}"
      outputs:
        artifacts:
          - name: pheno_csv
            path: /mnt/vol/pheno.csv.gz
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/{{pod.name}}/pheno.csv.gz"

    - name: get-cohort-middleware-csv-case-control
      inputs:
        parameters:
          - name: source_id
          - name: case_cohort_id
          - name: control_cohort_id
          - name: prefixed_concept_ids
          - name: gen3environment
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"
      container:
        image: quay.io/cdis/vadc-gwas-tools:master
        imagePullPolicy: Always
        command: ["/bin/bash", "-c"]
        args: ["/env/bin/vadc-gwas-tools GetCohortPheno --source_id {{inputs.parameters.source_id}} \
          --case_cohort_id {{inputs.parameters.case_cohort_id}} \
          --control_cohort_id {{inputs.parameters.control_cohort_id}} \
          -o /mnt/vol/pheno.csv.gz \
          --prefixed_concept_ids {{inputs.parameters.prefixed_concept_ids}}
        "]
        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
        resources:
          requests:
            cpu: 50m
            memory: 50Mi
          limits:
            cpu: 100m
            memory: 100Mi
        env:
          - name: GEN3_ENVIRONMENT
            value: "{{inputs.parameters.gen3environment}}"
      outputs:
        artifacts:
          - name: pheno_csv
            path: /mnt/vol/pheno.csv.gz
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/{{pod.name}}/pheno.csv.gz"

    - name: generate-pheno
      inputs:
        parameters:
          - name: prefixed_hare_concept_id
          - name: hare_population
        artifacts:
          - name: pheno_csv
            mode: 0777
            path: "/mnt/vol/phenotypes.csv.gz"
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"
      script:
        image: quay.io/cdis/topmed-master:2.12.0
        imagePullPolicy: IfNotPresent
        command: [Rscript]
        source: |
          library(Biobase)

          dat.csv <- read.csv(gzfile("{{inputs.artifacts.pheno_csv.path}}"),
                              stringsAsFactors=FALSE, na.strings=c("NA", ""))
          stopifnot("sample.id" %in% names(dat.csv))
          dat.csv$sample.id <- as.character(dat.csv$sample.id)

          # Filter to HARE population
          dat.csv <- subset(dat.csv, {{inputs.parameters.prefixed_hare_concept_id}} == "{{inputs.parameters.hare_population}}")

          # Remove NAs
          dat.csv <- na.omit(dat.csv)

          # Convert to AnnotatedDataFrame
          annot <- AnnotatedDataFrame(dat.csv)
          stopifnot("sample.id" %in% varLabels(annot))
          save(annot, file="/mnt/vol/phenotypes.Rdata")

        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
        resources:
          requests:
            cpu: 500m
            memory: 512Mi
          limits:
            cpu: 1000m
            memory: 2Gi
      outputs:
        artifacts:
          - name: phenotype_file
            path: "/mnt/vol/phenotypes.Rdata"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/{{pod.name}}/phenotypes.Rdata"

    - name: impute-score-filter
      inputs:
        parameters:
          - name: impute_cutoff
          - name: gds_file
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"
      script:
        image: quay.io/cdis/topmed-master:2.12.0
        imagePullPolicy: IfNotPresent
        command: [Rscript]
        source: |
          library(SeqVarTools)

          gdsFile <- "{{inputs.parameters.gds_file}}"
          imputation.cutoff <- {{inputs.parameters.impute_cutoff}}
          chrom <- gsub("(.*)(chr[0-9X]+)(.*)", "\\2", basename(gdsFile))
          cat("gds:", gdsFile, "chromosome:", chrom, "\n")

          dir.create("/mnt/vol/variant_lists")
          outFile <- file.path("/mnt/vol/variant_lists", paste0(chrom, ".selected_variants.RData"))

          gds <- seqOpen(gdsFile)

          all.variant.ids <- seqGetData(gds, "variant.id")
          imputation.fit <- seqGetData(gds, "annotation/info/R2")
          sel <- imputation.fit >= imputation.cutoff | is.na(imputation.fit)
          variant.ids <- all.variant.ids[sel]
          save(variant.ids, file=outFile)
          seqClose(gds)
          
          cat("Total variants:", length(all.variant.ids),
              "\nDropped variants:", length(all.variant.ids) - length(variant.ids),
              "\nRemaining variants (%):", length(variant.ids),
                  paste0("(", round(100*(length(variant.ids)/length(all.variant.ids)), 2), "%)"), "\n")

        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
          - name: gateway
            mountPath: /commons-data
        resources:
          requests:
            cpu: 500m
            memory: 512Mi
          limits:
            cpu: 1000m
            memory: 2Gi
      outputs:
        artifacts:
          - name: variant_list_dir
            path: "/mnt/vol/variant_lists"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/variant_lists"


    - name: run-null-model
      inputs:
        parameters:
          - name: n_pcs
          - name: covariates
          - name: out_prefix
          - name: outcome
          - name: outcome_is_binary
          - name: pca_file
          - name: relatedness_matrix_file
        artifacts:
          - name: phenotype_file
            mode: 0777
            path: "/mnt/vol/phenotypes.Rdata"
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"

      script:
        image: quay.io/cdis/topmed-master:2.12.0
        imagePullPolicy: IfNotPresent
        command: [bash]
        source: |
          export NSLOTS=2
          cd /mnt/vol


          echo "out_prefix {{inputs.parameters.out_prefix}}" > null_model.config
          echo "phenotype_file {{inputs.artifacts.phenotype_file.path}}" >> null_model.config
          echo "outcome {{inputs.parameters.outcome}}" >> null_model.config
          if [[ "{{inputs.parameters.outcome_is_binary}}" == "TRUE" ]]; then
                echo "family \"binomial\"" >> null_model.config
          else
                echo "family \"gaussian\"" >> null_model.config
          fi
          echo "n_pcs {{inputs.parameters.n_pcs}}" >> null_model.config
          echo "pca_file {{inputs.parameters.pca_file}}" >> null_model.config
          echo "relatedness_matrix_file {{inputs.parameters.relatedness_matrix_file}}" >> null_model.config
          echo "covars \"{{inputs.parameters.covariates}}\"" >> null_model.config
          echo "out_phenotype_file {{inputs.parameters.out_prefix}}_phenotypes.Rdata" >> null_model.config

          set -xe
          cat null_model.config

          Rscript /usr/local/analysis_pipeline/R/null_model.R null_model.config
          Rscript /usr/local/analysis_pipeline/R/null_model_report.R null_model.config --version 2.12.0
          ls -al

          DATADIR={{inputs.parameters.out_prefix}}_datadir
          mkdir $DATADIR
          mv {{inputs.parameters.out_prefix}}*.RData $DATADIR/

          REPORTDIR={{inputs.parameters.out_prefix}}_reports
          mkdir $REPORTDIR
          mv *.html $REPORTDIR/
          mv *.Rmd $REPORTDIR/

        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
          - name: gateway
            mountPath: /commons-data

        resources:
          requests:
            cpu: 2500m
            memory: 2Gi
          limits:
            cpu: 5000m
            memory: 5Gi

      outputs:
        artifacts:
          - name: null_model_directory
            path: "/mnt/vol/{{inputs.parameters.out_prefix}}_datadir"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/{{pod.name}}/{{inputs.parameters.out_prefix}}_datadir"
          - name: null_model_phenotype
            path: "/mnt/vol/{{inputs.parameters.out_prefix}}_phenotypes.Rdata"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/{{pod.name}}/{{inputs.parameters.out_prefix}}_phenotypes.Rdata"
          - name: null_model_report_directory
            path: "/mnt/vol/{{inputs.parameters.out_prefix}}_reports"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/{{pod.name}}/{{inputs.parameters.out_prefix}}_reports"

    - name: define-segments
      inputs:
        parameters:
          - name: genome_build
          - name: n_segments
          - name: segment_length
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"

      script:
        image: quay.io/cdis/topmed-master:2.12.0
        imagePullPolicy: IfNotPresent
        command: [bash]
        source: |
          cd /mnt/vol
          echo "genome_build {{inputs.parameters.genome_build}}" > define_segments.config
          echo "out_file segments.txt" >> define_segments.config

          if [[ "{{inputs.parameters.n_segments}}" == "0" ]]; then
              NSEG=""
          else
              NSEG=" --n_segments {{inputs.parameters.n_segments}}"
          fi

          Rscript /usr/local/analysis_pipeline/R/define_segments.R \
          define_segments.config \
          --segment_length {{inputs.parameters.segment_length}}${NSEG}

        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol

        resources:
          requests:
            cpu: 250m
            memory: 512Mi
          limits:
            cpu: 500m
            memory: 1Gi

      outputs:
        artifacts:
          - name: segment_file
            path: "/mnt/vol/segments.txt"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/{{pod.name}}/segments.txt"

    - name: split-filename
      inputs:
        parameters:
          - name: gds_file
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"
      container:
        image: quay.io/cdis/vadc-gwas-tools:master
        imagePullPolicy: Always
        command: ["/bin/bash", "-c"]
        args: ["/env/bin/vadc-gwas-tools SplitFilenameByChr \
          --gds_file {{inputs.parameters.gds_file}}
        "]
        resources:
          requests:
            cpu: 50m
            memory: 50Mi
          limits:
            cpu: 100m
            memory: 100Mi

    - name: filter-segments
      inputs:
        parameters:
          - name: gds_filenames
          - name: file_prefix
          - name: file_suffix
        artifacts:
          - name: segment_file
            path: "/mnt/vol/segments.txt"
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"
      container:
        image: quay.io/cdis/vadc-gwas-tools:master
        imagePullPolicy: Always
        command: ["/bin/bash", "-c"]
        args: ["/env/bin/vadc-gwas-tools FilterSegments \
          --file_prefix {{inputs.parameters.file_prefix}} \
          --file_suffix {{inputs.parameters.file_suffix}} \
          --segment_file {{inputs.artifacts.segment_file.path}} \
          {{=sprig.join(' ', map(jsonpath(inputs.parameters.gds_filenames, '$'), {#}))}}
        "]
        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
        resources:
          requests:
            cpu: 50m
            memory: 50Mi
          limits:
            cpu: 100m
            memory: 100Mi

    - name: run-single-assoc
      inputs:
        parameters:
          - name: gds_files
          - name: out_prefix
          - name: genome_build
          - name: file_prefix
          - name: file_suffix
          - name: segment
          - name: variant_block_size
          - name: mac_threshold
          - name: maf_threshold
          - name: outcome_is_binary
        artifacts:
          - name: segment_file
            mode: 0777
            path: "/mnt/vol/segments.txt"
          - name: null_model_results
            mode: 0777
            path: "/mnt/vol/null_model_results"
          - name: phenotype_file
            mode: 0777
            path: "/mnt/vol/phenotypes.RData"
          - name: variant_list_dir
            mode: 0777
            path: "/mnt/vol/variant_lists"
      retryStrategy:
        limit: "5"
        retryPolicy: "Always"

      script:
        image: quay.io/cdis/topmed-master:2.12.0
        imagePullPolicy: IfNotPresent
        securityContext:
          runAsUser: 0
        command: [bash]
        source: |
          cd /mnt/vol
          for fil in {{=sprig.join(" ", map(jsonpath(inputs.parameters.gds_files, '$'), {#}))}}; do
              ln -s $fil .
          done

          set -xe
          CHROM="$(awk 'NR=={{=asInt(inputs.parameters.segment) + 1}} {print $1}' {{inputs.artifacts.segment_file.path}})" 
          echo $CHROM

          echo "out_prefix {{inputs.parameters.out_prefix}}" > assoc_single.config
          echo "genome_build {{inputs.parameters.genome_build}}" >> assoc_single.config
          echo "gds_file \"{{inputs.parameters.file_prefix}} {{inputs.parameters.file_suffix}}\"" >> assoc_single.config
          echo "phenotype_file {{inputs.artifacts.phenotype_file.path}}" >> assoc_single.config
          echo "segment_file {{inputs.artifacts.segment_file.path}}" >> assoc_single.config
          echo "variant_block_size {{inputs.parameters.variant_block_size}}" >> assoc_single.config
          echo "variant_include_file {{inputs.artifacts.variant_list_dir.path}}/chr${CHROM}.selected_variants.RData" >> assoc_single.config
          if [[ "{{inputs.parameters.outcome_is_binary}}" == "TRUE" ]]; then
                echo "null_model_file {{inputs.artifacts.null_model_results.path}}/{{inputs.parameters.out_prefix}}_null_model.RData" >> assoc_single.config
                echo "test_type \"score.spa\"" >> null_model.config
          else
                echo "null_model_file {{inputs.artifacts.null_model_results.path}}/{{inputs.parameters.out_prefix}}_null_model_invnorm.RData" >> assoc_single.config
          fi

          if [[ "{{inputs.parameters.mac_threshold}}" == "0" ]]; then
              echo "mac_threshold NA" >> assoc_single.config
              echo "maf_threshold {{inputs.parameters.maf_threshold}}" >> assoc_single.config
          else
              echo "mac_threshold {{inputs.parameters.mac_threshold}}" >> assoc_single.config
          fi

          cat assoc_single.config
          ls -al

          Rscript /usr/local/analysis_pipeline/R/assoc_single.R assoc_single.config --chromosome $CHROM \
          --segment {{inputs.parameters.segment}} \
          --num_cores 1

          SEGOUT="{{inputs.parameters.out_prefix}}_chr${CHROM}_seg{{inputs.parameters.segment}}.RData"
          mkdir single_assoc_chunks

          if [[ -f $SEGOUT ]]; then
                mv $SEGOUT single_assoc_chunks/
          else
                echo "No outputs for segment... skipping..."
          fi

        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
          - name: gateway
            mountPath: /commons-data

        resources:
          requests:
            cpu: 1000m
            memory: 4Gi
          limits:
            cpu: 2000m
            memory: 8Gi
      outputs:
        artifacts:
          - name: single_assoc_segment_output
            path: "/mnt/vol/single_assoc_chunks"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/single_assoc_chunks"

    - name: combine-shards
      inputs:
        parameters:
          - name: chromosome
          - name: out_prefix
        artifacts:
          - name: file_shards
            mode: 0777
            path: "/mnt/vol/file_shards"
      retryStrategy:
        limit: "4"
        retryPolicy: "Always"

      script:
        image: quay.io/cdis/topmed-master:2.12.0
        imagePullPolicy: IfNotPresent
        securityContext:
          runAsUser: 0
        command: [bash]
        source: |
          cd {{inputs.artifacts.file_shards.path}}

          echo "out_prefix {{inputs.parameters.out_prefix}}" > assoc_combine.config
          echo "assoc_type \"single\"" >> assoc_combine.config

          cat assoc_combine.config
          ls -al

          set -xe
          Rscript /usr/local/analysis_pipeline/R/assoc_combine.R \
          assoc_combine.config \
          --chromosome {{inputs.parameters.chromosome}}
          mkdir single_assoc_combined
          mv {{inputs.parameters.out_prefix}}_chr{{inputs.parameters.chromosome}}.RData single_assoc_combined/

        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
        resources:
          requests:
            cpu: 1000m
            memory: 4Gi
          limits:
            cpu: 2000m
            memory: 8Gi
      outputs:
        artifacts:
          - name: single_assoc_combined
            path: "{{inputs.artifacts.file_shards.path}}/single_assoc_combined"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/single_assoc_combined"

    - name: run-plots
      inputs:
        parameters:
          - name: chromosomes
          - name: out_prefix
        artifacts:
          - name: combined
            mode: 0777
            path: "/mnt/vol/combined"
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"

      script:
        image: quay.io/cdis/topmed-master:2.12.0
        imagePullPolicy: IfNotPresent
        securityContext:
          runAsUser: 0
        command: [bash]
        source: |
          cd {{inputs.artifacts.combined.path}}

          echo "assoc_type \"single\"" > plots.config
          echo "thin \"TRUE\"" >> plots.config
          echo "assoc_file \"{{inputs.parameters.out_prefix}}_chr .RData\"" >> plots.config
          echo "chromosomes \"{{inputs.parameters.chromosomes}}\"" >> plots.config
          echo "out_file_manh \"{{inputs.parameters.out_prefix}}_manhattan.png\"" >> plots.config
          echo "out_file_qq \"{{inputs.parameters.out_prefix}}_qq.png\"" >> plots.config

          cat plots.config
          ls -al

          set -xe
          Rscript /usr/local/analysis_pipeline/R/assoc_plots.R plots.config

        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
        resources:
          requests:
            cpu: 250m
            memory: 1Gi
          limits:
            cpu: 1000m
            memory: 8Gi
      outputs:
        artifacts:
          - name: manhattan_plot
            path: "{{inputs.artifacts.combined.path}}/{{inputs.parameters.out_prefix}}_manhattan.png"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/gwas_plots/{{inputs.parameters.out_prefix}}_manhattan.png"
          - name: qq_plot
            path: "{{inputs.artifacts.combined.path}}/{{inputs.parameters.out_prefix}}_qq.png"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/gwas_plots/{{inputs.parameters.out_prefix}}_qq.png"

    - name: run-annotate
      inputs:
        parameters:
          - name: chromosome
          - name: out_prefix
        artifacts:
          - name: raw_stats
            mode: 0777
            path: "/mnt/vol/raw_stats.RData"
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"

      script:
        image: quay.io/cdis/topmed-master:2.12.0
        imagePullPolicy: IfNotPresent
        securityContext:
          runAsUser: 0
        command: [Rscript]
        source: |
          library(dplyr)

          # Load summary stats
          load("{{inputs.artifacts.raw_stats.path}}")

          # Load RSID meta
          anno.df <- read.delim("/commons-data/kmhernan/marker_metadata/vadc_mvp_marker_annotation.chr{{inputs.parameters.chromosome}}.rsids.tsv.gz",
                                header=TRUE,
                                stringsAsFactors=FALSE,
                                sep="\t")

          # Load var meta
          varmeta.df <- read.csv("/commons-data/kmhernan/marker_metadata/vadc_mvp_marker_annotation.chr{{inputs.parameters.chromosome}}.var_meta.csv.gz",
                                 stringsAsFactors=FALSE) %>%
            mutate(chr=as.character(chr))

          # Make annotated df
          annotated.summary.df <- varmeta.df %>%
            left_join(anno.df, by=c("variant.name"="variant.name")) %>%
            inner_join(assoc, by=c("variant.id"="variant.id", "chr"="chr", "pos"="pos")) %>%
            mutate(chr=paste0("chr", chr))

          # Write new CSV
          write.csv(annotated.summary.df,
            file=gzfile("/mnt/vol/{{inputs.parameters.out_prefix}}_chr{{inputs.parameters.chromosome}}.annotated_summary.csv.gz"),
            row.names=FALSE,
            na="")

        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
          - name: gateway
            mountPath: /commons-data
        resources:
          requests:
            cpu: 250m
            memory: 1Gi
          limits:
            cpu: 500m
            memory: 4Gi
      outputs:
        artifacts:
          - name: annotated_stats_csv
            path: "/mnt/vol/{{inputs.parameters.out_prefix}}_chr{{inputs.parameters.chromosome}}.annotated_summary.csv.gz"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/annotated_csvs/{{inputs.parameters.out_prefix}}_chr{{inputs.parameters.chromosome}}.annotated_summary.csv.gz"

    - name: get-gwas-metadata
      inputs:
        parameters:
          - name: source_id
          - name: case_cohort_id
          - name: control_cohort_id
          - name: prefixed_outcome_concept_id
          - name: prefixed_concept_ids
          - name: internal_api_env
          - name: n_pcs
          - name: maf_threshold
          - name: imputation_score_cutoff
          - name: hare_population
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"
      script:
        image: quay.io/cdis/vadc-gwas-tools:master
        imagePullPolicy: Always
        command: [/bin/bash]
        source: |
          if [[ "{{inputs.parameters.control_cohort_id}}" == "-1" ]]; then
              CONCEPT_IDS="{{inputs.parameters.prefixed_outcome_concept_id}} {{inputs.parameters.prefixed_concept_ids}}"
              OUTCOME_ID=" --prefixed_outcome_concept_id {{inputs.parameters.prefixed_outcome_concept_id}}"
          else
              CONCEPT_IDS="{{inputs.parameters.prefixed_concept_ids}}"
              OUTCOME_ID=" --control_cohort_id {{inputs.parameters.control_cohort_id}}"
          fi

          /env/bin/vadc-gwas-tools GetGwasMetadata \
          --source_id {{inputs.parameters.source_id}} \
          --case_cohort_id {{inputs.parameters.case_cohort_id}} \
          --prefixed_concept_ids ${CONCEPT_IDS}${OUTCOME_ID} \
          --n_pcs {{inputs.parameters.n_pcs}} \
          --maf_threshold {{inputs.parameters.maf_threshold}} \
          --imputation_score_cutoff {{inputs.parameters.imputation_score_cutoff}} \
          --hare_population "{{inputs.parameters.hare_population}}" \
          --output /mnt/vol/{{workflow.name}}.gwas_metadata.yaml

        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
        env:
          - name: GEN3_ENVIRONMENT
            value: "{{inputs.parameters.internal_api_env}}"
      outputs:
        artifacts:
          - name: gwas_metadata
            path: /mnt/vol/{{workflow.name}}.gwas_metadata.yaml
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/{{pod.name}}/{{workflow.name}}.gwas_metadata.yaml"

    - name: run-tar
      inputs:
        parameters:
          - name: out_prefix
        artifacts:
          - name: manhattan_plot
            path: "/mnt/vol/{{workflow.name}}/{{inputs.parameters.out_prefix}}_manhattan.png"
          - name: qq_plot 
            path: "/mnt/vol/{{workflow.name}}/{{inputs.parameters.out_prefix}}_qq.png"
          - name: annotated_csvs
            mode: 0777
            path: "/mnt/vol/{{workflow.name}}/annotated_summary_csvs"
          - name: gwas_metadata
            path: "/mnt/vol/{{workflow.name}}/{{workflow.name}}.gwas_metadata.yaml"
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"

      script:
        image: alpine:latest
        imagePullPolicy: IfNotPresent
        command: [/bin/sh]
        source: |
          cd /mnt/vol
          tar -czf {{workflow.name}}.tar.gz {{workflow.name}}/

        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
        resources:
          requests:
            cpu: 250m
            memory: 500Mi
          limits:
            cpu: 500m
            memory: 1Gi

      outputs:
        artifacts:
          - name: gwas_archive
            path: "/mnt/vol/{{workflow.name}}.tar.gz"
            archive:
              none: {}
            s3:
              endpoint: s3.amazonaws.com
              bucket: argo-artifact-storage-downloadable 
              key: "{{workflow.name}}/{{workflow.name}}.tar.gz"
              accessKeySecret:
                name: argo-s3-creds
                key: AccessKeyId
              secretKeySecret:
                name: argo-s3-creds
                key: SecretAccessKey

    - name: gen-indexd-meta
      inputs:
        parameters:
          - name: arborist_resource
        artifacts:
          - name: gwas_archive
            path: /mnt/vol/archive.tar.gz
      script:
        image: python:3.7
        imagePullPolicy: IfNotPresent
        command: [python3]
        source: |
          import json
          import hashlib
          import os

          def get_md5_sum(fil):
              md5 = hashlib.md5()
              with open(fil, 'rb') as fh:
                  while True:
                      r = fh.read(8192)
                      if not r:
                          break
                      md5.update(r)
              return {"md5": str(md5.hexdigest())}

          if __name__ == '__main__':
              hash_meta = get_md5_sum("{{inputs.artifacts.gwas_archive.path}}")
              fsize = int(os.stat("{{inputs.artifacts.gwas_archive.path}}").st_size)
              data = {
                "authz": ["{{inputs.parameters.arborist_resource}}"],
                "file_name": "{{workflow.name}}.tar.gz",
                "hashes": hash_meta,
                "size": fsize,
                "urls": ["s3://argo-artifact-storage-downloadable/{{workflow.name}}/{{workflow.name}}.tar.gz"],
                "urls_metadata": {
                        "s3://argo-artifact-storage-downloadable/{{workflow.name}}/{{workflow.name}}.tar.gz": {}
                },
                "form": "object"
              }
              with open("/mnt/vol/record.json", 'wt') as o:
                  json.dump(data, o)
        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
        resources:
          requests:
            cpu: 50m
            memory: 50Mi
          limits:
            cpu: 100m
            memory: 100Mi
      outputs:
        artifacts:
          - name: indexd_record
            path: "/mnt/vol/record.json" 
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/{{pod.name}}/indexd_record.json"

    - name: gen-indexd-record
      inputs:
        artifacts:
          - name: request_data
            path: /mnt/vol/request.json
      script:
        image: alpine/curl:3.14
        imagePullPolicy: IfNotPresent
        command: [sh]
        source: |
          AUTH=$(echo -ne "$INDEXDUSER:$INDEXDPASS" | base64 -w 0)
          curl \
          --header "Content-Type: application/json" \
          --header "Authorization: Basic $AUTH" \
          --request POST --data "@/mnt/vol/request.json" http://indexd-service.default/index > /mnt/vol/did.json
        env:
          - name: INDEXDUSER
            valueFrom:
              secretKeyRef:
                name: indexd-creds
                key: user
          - name: INDEXDPASS
            valueFrom:
              secretKeyRef:
                name: indexd-creds
                key: password
        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
        resources:
          requests:
            cpu: 50m
            memory: 50Mi
          limits:
            cpu: 100m
            memory: 100Mi
      outputs:
        parameters:
          - name: gwas_archive_index
            valueFrom:
              path: /mnt/vol/did.json
            globalName: gwas_archive_index
