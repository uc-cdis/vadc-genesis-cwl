apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: meta-template-annotations
  annotations:
    workflow_name: "Meta-Analysis Workflow"
    version: 0.0.4
    description: |
      * Add annotations
spec:
  # must complete in 8h (28,800 seconds)
  activeDeadlineSeconds: 28800
  # keep workflow for 10 seconds
  ttlStrategy:
    secondsAfterCompletion: 10
  podMetadata:
    annotations:
      karpenter.sh/do-not-evict: "true"
  entrypoint: meta-analysis
  templates:
    - name: meta-analysis
      inputs:
        parameters:
          - name: internal_api_env
            default: default
          - name: team_project
          - name: maf_threshold
            default: 0.01
          - name: gwas_list
          - name: chromosome_list
            value: |-
              [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, "X"]
      dag:
        tasks:
        
          # Get downloadable bucket
          - name: get-downloadable-bucket
            template: get-downloadable-bucket

          # Save inputs in json
          - name: pass-inputs
            template: pass-inputs

          # Get data gwas and chromosome data from downloadable bucket, unzip it and save
          - name: process-inputs
            template: process-inputs
            dependencies: [get-downloadable-bucket, pass-inputs]
            arguments:
              parameters:
                - name: downloadable_bucket
                  value: "{{tasks.get-downloadable-bucket.outputs.parameters.downloadable_bucket}}"
                - name: gwas
                  value: "{{item}}"
            withParam: "{{inputs.parameters.gwas_list}}"

          # Format data for METAL analysis per gwas
          - name: format-data
            template: format-data
            dependencies: [process-inputs]
            arguments:
              parameters:
                - name: gwas
                  value: "{{item}}"
              artifacts:
                - name: gwas_chromosome_data
                  s3:
                    key: "{{workflow.name}}/gwas_chromosome_data"
            withParam: "{{inputs.parameters.gwas_list}}"

          # Run METAL analysis per chromosome
          - name: run-analysis
            template: run-analysis
            dependencies: [format-data]
            arguments:
              parameters:
                - name: chromosome
                  value: "{{item}}"
              artifacts:
                - name: formatted_data
                  s3:
                    key: "{{workflow.name}}/formatted_data"
            withParam: "{{inputs.parameters.chromosome_list}}"

          # Annotate meta-analysis results
          - name: annotate-statistics
            template: annotate-statistics
            dependencies: [run-analysis]
            arguments:
              parameters:
                - name: chromosome
                  value: "{{item}}"
              artifacts:
                - name: meta_analysis
                  s3:
                    key: "{{workflow.name}}/meta_analysis"
            withParam: "{{inputs.parameters.chromosome_list}}"

          # Create Manhattan and QQ plots
          - name: create-plots
            template: create-plots
            dependencies: [annotate-statistics]
            arguments:
              artifacts:
                - name: meta_analysis
                  s3:
                    key: "{{workflow.name}}/meta_analysis_annotated"

          # Combine data for the pheweb
          - name: combine-pheweb
            template: combine-pheweb
            dependencies: [annotate-statistics]
            arguments:
              artifacts:
                - name: meta_analysis
                  s3:
                    key: "{{workflow.name}}/meta_analysis_annotated"

          # Create pheweb json file
          - name: create-pheweb-json
            template: create-pheweb-json
            dependencies: [combine-pheweb]
            arguments:
              parameters:
                - name: downloadable_bucket
                  value: "{{tasks.get-downloadable-bucket.outputs.parameters.downloadable_bucket}}"
              artifacts:
                - name: pheweb_tsv
                  from: "{{tasks.combine-pheweb.outputs.artifacts.pheweb_tsv}}"

          # Archive outputs
          - name: archive-outputs
            template: archive-outputs
            dependencies: [create-plots]
            arguments:
              parameters:
                - name: downloadable_bucket
                  value: "{{tasks.get-downloadable-bucket.outputs.parameters.downloadable_bucket}}"
              artifacts:
                - name: meta_analysis
                  s3:
                    key: "{{workflow.name}}/meta_analysis_annotated"
                - name: workflow_inputs_json
                  s3:
                    key: "{{workflow.name}}/workflow_inputs.json"
                - name: manhattan_plot
                  s3:
                    key: "{{workflow.name}}/manhattan.png"
                - name: qq_plot
                  s3:
                    key: "{{workflow.name}}/qq.png"
           
          # Create indexd records
          - name: create-indexd-record
            template: create-indexd-record
            dependencies: [archive-outputs, create-pheweb-json]
            arguments:
              parameters:
                - name: arborist_resource
                  value: "{{inputs.parameters.team_project}}"
                - name: internal_api_env
                  value: "{{inputs.parameters.internal_api_env}}"
                - name: downloadable_bucket
                  value: "{{tasks.get-downloadable-bucket.outputs.parameters.downloadable_bucket}}"
              artifacts:
                - name: meta_analysis_archive
                  from: "{{tasks.archive-outputs.outputs.artifacts.meta_analysis_archive}}"           
                - name: pheweb_manhattan_json
                  from: "{{tasks.create-pheweb-json.outputs.artifacts.pheweb_manhattan_json}}" 
                - name: pheweb_qq_json
                  from: "{{tasks.create-pheweb-json.outputs.artifacts.pheweb_qq_json}}" 

    # Define each step
    # Get downloadable bucket
    - name: get-downloadable-bucket
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"
      script:
        image: quay.io/cdis/post_gwas:0.0.9
        imagePullPolicy: IfNotPresent
        command: [/bin/bash]
        source: |
          echo "Bash version:"
          echo $(bash --version)

          echo "Locale:"
          echo $(locale)

          if [ -z $DOWNLOADABLE_BUCKET ]; then
            echo "Downloadable bucket is not found or set to empty string"
            exit 1
          else
            echo "Downloadable bucket found: $DOWNLOADABLE_BUCKET"
            echo "$DOWNLOADABLE_BUCKET" > /mnt/vol/downloadable_bucket.txt
          fi
          
          # Check if downloadble bucket is accessible
          aws s3api head-bucket --bucket $DOWNLOADABLE_BUCKET
          if [ $? -ne 0 ]; then
            echo "AWS command failed: bucket $DOWNLOADABLE_BUCKET not found or not accessible"
            exit 1
          else
            echo "AWS command succeeded: bucket $DOWNLOADABLE_BUCKET found and is accessible"
          fi         
        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
        resources:
          requests:
            cpu: 250m
            memory: 512Mi
          limits:
            cpu: 500m
            memory: 1Gi
        env:
        - name: DOWNLOADABLE_BUCKET
          valueFrom:
            secretKeyRef:
              name: argo-template-values-secret
              key: DOWNLOADABLE_BUCKET
      outputs:
        parameters:
          - name: downloadable_bucket
            valueFrom:
              path: "/mnt/vol/downloadable_bucket.txt"

    # Save inputs in json
    - name: pass-inputs
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"
      script:
        image: quay.io/cdis/post_gwas:0.0.9
        imagePullPolicy: IfNotPresent
        command: [/bin/bash]
        source: |
            set -xe
            echo '{
              "meta_analysis_id": "{{workflow.name}}",
              "meta_analysis_name": "{{workflow.annotations.workflow_name}}",
              "gwas_list": {{workflow.parameters.gwas_list}},
              "maf_threshold": {{workflow.parameters.maf_threshold}}
            }' | jq -r . > /mnt/vol/workflow_inputs.json
        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
        resources:
          requests:
            cpu: 250m
            memory: 512Mi
          limits:
            cpu: 500m
            memory: 1Gi
      outputs:
        artifacts:
          - name: workflow_inputs_json
            path: /mnt/vol/workflow_inputs.json
            archive: 
              none: {}
            s3:
              key: "{{workflow.name}}/workflow_inputs.json"

    # Get data gwas and chromosome data from downloadable bucket, unzip it and save  
    - name: process-inputs
      inputs: 
        parameters:
          - name: downloadable_bucket
          - name: gwas
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"
      script:
        image: quay.io/cdis/post_gwas:0.0.9
        imagePullPolicy: IfNotPresent
        command: [/bin/bash]
        source: |
          echo "Bash version:"
          echo $(bash --version)

          echo "Locale:"
          echo $(locale)

          set -e
          cd /mnt/vol
          echo "Switched to the working directory /mnt/vol"

          bucket={{inputs.parameters.downloadable_bucket}}
          gwas={{inputs.parameters.gwas}}
          echo "Bucket parameter received: $bucket"
          echo "GWAS parameter received: $gwas"

          # Transform chromosome_list
          chromosome_list='{{workflow.parameters.chromosome_list}}'
          chromosome_list=$(echo $chromosome_list | jq -r '.[]')
          readarray -t chromosome_list <<< "$chromosome_list"

          # Check if workflow is accessible and if it is, copy the data
          if [[ $(aws s3 ls s3://$bucket/$gwas/ | head) ]]; then
            echo "AWS command succeeded: folder $gwas found and is accessible"
            aws s3 cp s3://$bucket/$gwas/$gwas.zip .
            echo "AWS command succeeded: copied $gwas.zip to the working directory"
            ls -la
            unzip $gwas.zip
            echo "$gwas.zip was unzipped"
            rm $gwas.zip
            echo "$gwas.zip was removed"
            ls -la
            
            mkdir gwas_chromosome_data
            echo "Created folder gwas_chromosome_data"

            csv_path=$gwas/annotated_summary_csvs/

            for chr in ${chromosome_list[@]}
            do
              # Find file in cvs_path
              substring="_chr$chr.annotated_summary.csv.zip"
              zip_filepath=$(find $csv_path -name "*$substring*" -type f -print -quit)
              zip_filename=$(basename $zip_filepath)
              echo "CSV name $filename"
              # Unzip file
              echo "Unzipping file $zip_filepath"
              unzip $zip_filepath
              echo "File $zip_filepath unzipped"
              #ls -la
              # Get CSV filename by removing zip extension
              csv_filename="${zip_filename%.*}"
              # Create a new filename for the CSV containing gwas id
              gwas_csv_filename=$gwas.chr$chr.annotated_summary.csv
              # Rename CSV file
              echo "Renaming file $csv_filename to $gwas_csv_filename"
              mv $csv_filename $gwas_csv_filename
              echo "File $csv_filename renamed to $gwas_csv_filename"
              #ls -la
              # Take a look at the file
              #echo "Head of $gwas_csv_filename:"
              #head $gwas_csv_filename
              # Save in gwas_chromosome_data
              mv $gwas_csv_filename gwas_chromosome_data
              echo "$gwas_csv_filename moved to gwas_chromosome_data folder"
              #ls -la gwas_chromosome_data/
            done

            echo "Removing $gwas folder from /mnt/vol"
            #ls -la
            rm -r $gwas
            echo "$gwas folder was removed from the working directory /mnt/vol"
            #ls -la
            echo "Content of gwas_chromosome_data folder"
            ls -la gwas_chromosome_data/
          else
            echo "AWS command failed: folder $gwas not found or not accessible"
            exit 1
          fi
          echo "All done!"
        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
      outputs:
        artifacts:
          - name: gwas_chromosome_data
            path: "/mnt/vol/gwas_chromosome_data"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/gwas_chromosome_data"

    # Format data for METAL analysis per gwas
    - name: format-data
      inputs: 
        parameters:
          - name: gwas
        artifacts:
          - name: gwas_chromosome_data
            path: "/mnt/vol/gwas_chromosome_data"
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"
      script:
        image: quay.io/cdis/post_gwas:0.0.9
        imagePullPolicy: IfNotPresent
        command: [Rscript]
        source: |
          library(jsonlite)
          library(data.table)

          noquote("R.version:")
          print(R.version)
          
          noquote("Locale:")
          print(Sys.getlocale(category = "LC_ALL"))
          
          vectorize_json = Vectorize(fromJSON)

          gwas <- "{{inputs.parameters.gwas}}"
          datadir <- "{{inputs.artifacts.gwas_chromosome_data.path}}"
          chromosome_list <- vectorize_json('{{workflow.parameters.chromosome_list}}')

          noquote("GWAS parameter received:")
          print(gwas)
          noquote("GWAS chromosome data parameter received:")
          print(datadir)
          noquote("Chromosome list parameter derived from workflow parameters:")
          print(chromosome_list)
          
          setwd("/mnt/vol")
          dir.create("formatted_data")
          formatted_folder="/mnt/vol/formatted_data/"
          noquote("Created formatted_data folder:")
          print(list.files())
          
          setwd(datadir)
          noquote("GWAS chromosome data folder:")
          print(list.files())
          
          gwas_file_pattern <- paste0("^", gwas, ".chr")
          noquote("GWAS related files:")
          print(list.files(pattern=gwas_file_pattern))

          keep_columns=c("variant.name", "ref", "alt", "freq", "Est", "Est.SE", "chr", "pos")
          for (chr in chromosome_list) {
            print("Formatting CSV for chromosome:")
            print(chr)
            input_filename <- paste0(gwas, ".chr", chr, ".annotated_summary.csv")
            output_filename <- paste0(formatted_folder, gwas, ".chr", chr, ".annotated_summary.csv")
            print("Reading CSV file:")
            print(input_filename)
            print("Keeping columns:")
            print(keep_columns)
            chromosome_data <- fread(input_filename, select=keep_columns)
            print("Chromosome data dimensions:")
            print(dim(chromosome_data))
            write.table(chromosome_data, output_filename, sep=",", row.name=FALSE)
            print("Formatted data saved in CSV:")
            print(output_filename)
            file.remove(input_filename)
            print("Initial CSV file removed:")
            print(input_filename)
          }
          
          noquote("All chromosome files converted for gwas:")
          print(gwas)

          noquote("Content of the formatted_data folder")
          print(list.files(formatted_folder, pattern=gwas_file_pattern))

          noquote("All done!")
        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
        resources:
          requests:
            cpu: 1000m
            memory: 2Gi
          limits:
            cpu: 2000m
            memory: 4Gi
      outputs:
        artifacts:
          - name: formatted_data
            path: "/mnt/vol/formatted_data"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/formatted_data"

    # Run METAL analysis per chromosome
    - name: run-analysis
      inputs: 
        parameters:
          - name: chromosome
        artifacts:
          - name: formatted_data
            path: "/mnt/vol/formatted_data"
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"
      script:
        image: quay.io/cdis/post_gwas:0.0.9
        imagePullPolicy: IfNotPresent
        command: [/bin/bash]
        source: |
          echo "Bash version:"
          echo $(bash --version)

          echo "Locale:"
          echo $(locale)

          set -e
          cd /mnt/vol

          chr={{inputs.parameters.chromosome}}
          datadir={{inputs.artifacts.formatted_data.path}}
          gwas_list='{{workflow.parameters.gwas_list}}'
          maf={{workflow.parameters.maf_threshold}}
          
          # Transform gwas_list
          gwas_list=$(echo $gwas_list | jq -r '.[]')
          readarray -t gwas_list <<< "$gwas_list"
          
          echo "Chromosome parameter received: $chr"
          echo "GWAS chromosome data parameter received: $datadir"
          echo "GWAS parameter derived from workflow parameters: ${gwas_list[@]}"
          echo "MAF threshold parameter derived from workflow parameters: $maf"

          echo "Creating metal_confg folder"
          mkdir metal_config
          ls -la
          pwd
          echo "Creating config_chr$chr.txt file in /mnt/vol/metal_config"
          CONFIG="/mnt/vol/metal_config/config_chr$chr.txt"
          touch $CONFIG
          
          echo "Switching to $datadir"
          cd $datadir
          echo "Formatted data:"
          ls -la         

          echo "Adding metal configuration to the /mnt/vol/metal_config/config_chr$chr.txt file"
          echo "# === DESCRIBE INPUT FILES ===" >> $CONFIG
          echo "SCHEME STDERR" >> $CONFIG
          echo "MARKER \"variant.name\"" >> $CONFIG
          echo "ALLELE \"ref\" \"alt\"" >> $CONFIG
          echo "FREQ \"freq\"" >> $CONFIG
          echo "EFFECT \"Est\"" >> $CONFIG
          echo "STDERR \"Est.SE\"" >> $CONFIG
          echo "CHROMOSOME \"chr\"" >> $CONFIG
          echo "POSITION \"pos\"" >> $CONFIG
          echo "COLUMNCOUNTING STRICT" >> $CONFIG
          echo "SEPARATOR COMMA" >> $CONFIG
          echo "TRACKPOSITIONS ON" >> $CONFIG
          echo "AVERAGEFREQ ON" >> $CONFIG
          echo "MINMAXFREQ ON" >> $CONFIG
          echo "ADDFILTER \"freq\" > $maf" >> $CONFIG

          echo "# === PROCESS INPUT FILES ===" >> $CONFIG
          for gwas in ${gwas_list[@]}
          do
            gwas_chr_filename=$gwas.chr$chr.annotated_summary.csv
            echo "PROCESS $gwas_chr_filename" >> $CONFIG
          done

          echo "# === ANALYZE INPUT FILES ===" >> $CONFIG
          echo "OUTFILE meta_analysis.chr$chr. .tbl" >> $CONFIG
          echo "ANALYZE HETEROGENEITY" >> $CONFIG
          echo "QUIT" >> $CONFIG

          echo "Configuration for chromosome $chr"
          less $CONFIG

          echo "Running analysis"
          metal $CONFIG
          echo "Analysis completed" 

          mkdir /mnt/vol/meta_analysis
          mv meta_analysis.chr$chr* /mnt/vol/meta_analysis/
          echo "Output tbl file moved to /mnt/vol/meta_analysis/"
          ls -la /mnt/vol/meta_analysis/
          echo "All done!"
        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
        resources:
          requests:
            cpu: 1000m
            memory: 2Gi
            ephemeral-storage: 4Gi
          limits:
            cpu: 2000m
            memory: 4Gi
            ephemeral-storage: 8Gi
      outputs:
        artifacts:
          - name: meta_analysis
            path: "/mnt/vol/meta_analysis"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/meta_analysis"
          - name: metal_config
            path: "/mnt/vol/metal_config"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/metal_config"
          - name: metal_config_chr{{inputs.parameters.chromosome}}
            path: "/mnt/vol/metal_config/config_chr{{inputs.parameters.chromosome}}.txt"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/metal_config/config_chr{{inputs.parameters.chromosome}}.txt"

    # Annotate meta-analysis results
    - name: annotate-statistics
      inputs:
        parameters:
          - name: chromosome
        artifacts:
          - name: meta_analysis
            path: "/mnt/vol/meta_analysis"
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"
      script:
        image: quay.io/cdis/post_gwas:0.0.9
        imagePullPolicy: IfNotPresent
        command: [Rscript]
        source: |
          library(data.table)

          noquote("R.version:")
          print(R.version)

          print(Sys.getlocale(category = "LC_ALL"))
          
          chromosome <- "{{inputs.parameters.chromosome}}"
          noquote("Chromosome received:")
          print(chromosome)
          setwd("/mnt/vol/meta_analysis")
          noquote("Meta analysis results received:")
          print(list.files())

          setwd("/mnt/vol")
          dir.create("meta_analysis_annotated")
          noquote("Created meta_analysis_annotated folder")
          input_folder <- "/mnt/vol/meta_analysis/"
          output_folder <- "/mnt/vol/meta_analysis_annotated/"

          meta_filename <- paste0("meta_analysis.chr", chromosome, ".1.tbl")
          input_filename <- paste0(input_folder, meta_filename)
          output_filename <- paste0(output_folder, meta_filename)

          # Load chromosome meta-analysis results
          noquote("Reading choromosome meta-analysis results:")
          print(input_filename)
          chromosome_meta <- fread(input_filename)
          print(dim(chromosome_meta))
          #print(head(chromosome_meta))

          # Load RSID meta
          noquote("Reading RSIDs data:")
          rsid_meta <- read.delim("/commons-data/kmhernan/marker_metadata/vadc_mvp_marker_annotation.chr{{inputs.parameters.chromosome}}.vep.tsv.gz",
                                header=TRUE,
                                stringsAsFactors=FALSE,
                                sep="\t")
          print(dim(rsid_meta))
          #print(head(rsid_meta))

          noquote("Adding annotations:")
          annotated_chromosome_meta <- merge(chromosome_meta, rsid_meta, by.x="MarkerName", by.y="variant.name", all.x=TRUE)
          print(dim(annotated_chromosome_meta))
          #print(head(annotated_chromosome_meta))

          # write pheweb TSV
          noquote("Saving annotated choromosome data:")
          write.table(annotated_chromosome_meta,
            file=output_filename,
            quote=TRUE,
            sep="\t",
            row.names=FALSE,
            na="")
          print(output_filename)

          noquote("Adding information file to the meta_analysis_annotated:")
          info_filename <- paste0("meta_analysis.chr", chromosome, ".1.tbl.info")
          input_filename <- paste0(input_folder, info_filename)
          output_filename <- paste0(output_folder, info_filename)
          file.copy(input_filename, output_filename)

          noquote("Adding annotations information to the information file:")
          cat("# Annotations added by VADC pipeline:", sep = "\n", file=output_filename, append = TRUE)
          cat("# rsids\t\t\t\t\t- standardized reference SNP IDs", sep = "\n", file=output_filename, append = TRUE)
          cat("# nearest_genes\t- gene symbols 5000 base pairs upstream and downstream of the Marker", sep = "\n", file=output_filename, append = TRUE)
          print(output_filename)

          noquote("All done!")
        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
          - name: gateway
            mountPath: /commons-data
        resources:
          requests:
            cpu: 1000m
            memory: 2Gi
            ephemeral-storage: 4Gi
          limits:
            cpu: 2000m
            memory: 4Gi
            ephemeral-storage: 8Gi
      outputs:
        artifacts:
          - name: meta_analysis_annotated
            path: "/mnt/vol/meta_analysis_annotated"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/meta_analysis_annotated"

    # Create Manhattan and QQ plots
    - name: create-plots
      inputs:
        artifacts:
          - name: meta_analysis
            mode: 511
            path: "/mnt/vol/meta_analysis"
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"
      script:
        image: quay.io/cdis/post_gwas:0.0.9
        imagePullPolicy: IfNotPresent
        command: [Rscript]
        source: |
          library(data.table)
          library(qqman)
          library(RColorBrewer)

          noquote("R.version:")
          print(R.version)

          print(Sys.getlocale(category = "LC_ALL"))
          
          setwd("/mnt/vol/meta_analysis")
          noquote("Meta analysis results received:")
          print(list.files())

          # Order files
          meta_results_filter <- sapply(c(1:22, "X"), function(x){ paste0("meta_analysis.chr", x, ".1.tbl")})
          file_names <- Filter(function(x) file.exists(x), meta_results_filter)

          noquote("Files for Manhattan and QQ plots:")
          print(file_names)
          keep_columns <- c("MarkerName", "P-value", "Chromosome", "Position")
          noquote("Columns to keep:")
          print(keep_columns)
          combined_dataframe <- do.call(rbind, lapply(file_names, fread, select=keep_columns))
          noquote("Initial combined dataframe created, dimensions:")
          print(dim(combined_dataframe))

          combined_dataframe$ChromosomeNumber <- substring(combined_dataframe$Chromosome, 4)
          chr_labs <- unique(combined_dataframe$ChromosomeNumber)
          combined_dataframe$ChromosomeNumber[combined_dataframe$ChromosomeNumber == "X"] <- 23
          combined_dataframe$ChromosomeNumber <- as.numeric(combined_dataframe$ChromosomeNumber)
          combined_dataframe$Snp <- NA
          noquote("Combined dataframe formatted, dimensions:")
          print(dim(combined_dataframe))

          combined_dataframe$`P-value` <- as.numeric(combined_dataframe$`P-value`)
          noquote("Markers with P-value below minimal possible for R double numeric 2e-308:")
          print(combined_dataframe[`P-value` < 2e-308, ])
          combined_dataframe$`P-value`[combined_dataframe$`P-value` == 0] <- 2e-308
          noquote("Assigned minimal possible R double numeric 2e-308 for markers with P-value below:")
          print(combined_dataframe[`P-value` == 2e-308, ])

          chr <- unique(combined_dataframe$ChromosomeNumber)
          cmap <- setNames(rep_len(brewer.pal(8, "Dark2"), length(chr)), chr)

          setwd("/mnt/vol/")
          png("manhattan.png", width=10, height=5, units="in", res=300)
          manhattan(combined_dataframe, 
                    chr="ChromosomeNumber", bp="Position",
                    snp="Snp", p="P-value",
                    chrlabs=chr_labs,
                    col=cmap,
                    suggestiveline=FALSE,
                    cex.axis=0.8,
                    cex.lab=0.8
                    )
          dev.off()
          noquote("Manhattan plot created:")
          print(list.files())

          png("qq.png", width=6, height=6, units="in", res=300)
          qq_plot <- qq(combined_dataframe$`P-value`)
          dev.off()
          noquote("QQ plot created:")
          print(list.files())

          noquote("All done!")
        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
        resources:
          requests:
            cpu: 1000m
            memory: 4Gi
          limits:
            cpu: 2000m
            memory: 8Gi
      outputs:
        artifacts:
          - name: manhattan_plot
            path: "/mnt/vol/manhattan.png"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/manhattan.png"        
          - name: qq_plot
            path: "/mnt/vol/qq.png"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/qq.png"    

    # Combine data for the pheweb
    - name: combine-pheweb
      inputs:
        artifacts:
          - name: meta_analysis
            mode: 511
            path: "/mnt/vol/meta_analysis"
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"
      script:
        image: quay.io/cdis/post_gwas:0.0.9
        imagePullPolicy: IfNotPresent
        command: [Rscript]
        source: |
          library(data.table)

          noquote("R.version:")
          print(R.version)

          print(Sys.getlocale(category = "LC_ALL"))

          setwd("/mnt/vol/meta_analysis")
          noquote("Meta analysis results received:")
          print(list.files())

          # Order files
          meta_results_filter <- sapply(c(1:22, "X"), function(x){ paste0("meta_analysis.chr", x, ".1.tbl")})
          file_names <- Filter(function(x) file.exists(x), meta_results_filter)

          # Combine
          keep_columns <- c("Chromosome", "Position", "Allele1", "Allele2", 
            "P-value", "Effect", "StdErr", "Freq1", "rsids", "nearest_genes")
          print("Keeping columns:")
          print(keep_columns)
          combined_dataframe <- do.call(rbind, lapply(file_names, fread, select=keep_columns))
          noquote("Combined dataframe:")
          print(head(combined_dataframe))
          colnames(combined_dataframe) <- c("chrom", "pos", "ref", "alt",
            "pval", "beta", "sebeta", "af", "rsids", "nearest_genes")
          combined_dataframe$chrom <- substring(combined_dataframe$chrom, 4)
          #combined_dataframe$chrom <- as.numeric(combined_dataframe$chrom)

          noquote("Formatted combined dataframe:")
          print(head(combined_dataframe))

          # write pheweb TSV
          write.table(combined_dataframe,
            file=gzfile("/mnt/vol/pheweb.tsv.gz"),
            quote=FALSE,
            sep="\t",
            row.names=FALSE,
            na="")
          
          noquote("Pheweb data saved in pheweb.tsv.gz")
          
          noquote("All done!")
        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
        resources:
          requests:
            cpu: 250m
            memory: 4Gi
          limits:
            cpu: 500m
            memory: 10Gi
      outputs:
        artifacts:
          - name: pheweb_tsv 
            path: "/mnt/vol/pheweb.tsv.gz"
            archive:
              none: {}
            s3:
              key: "{{workflow.name}}/pheweb.tsv.gz"
  
    - name: create-pheweb-json
      inputs:
        parameters:
          - name: downloadable_bucket
        artifacts:
          - name: pheweb_tsv
            path: "/mnt/vol/pheweb.tsv.gz"
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"
      script:
        image: 707767160287.dkr.ecr.us-east-1.amazonaws.com/gen3/vadc-gwas-tools:1.2.7
        imagePullPolicy: IfNotPresent
        command: ["/bin/bash"]
        source: |
          /env/bin/vadc-gwas-tools GetPheWebPlotJson \
          --in_tsv {{inputs.artifacts.pheweb_tsv.path}} \
          --out_json /mnt/vol/pheweb.manhattan.json \
          --out_plot_type manhattan

          /env/bin/vadc-gwas-tools GetPheWebPlotJson \
          --in_tsv {{inputs.artifacts.pheweb_tsv.path}} \
          --out_json /mnt/vol/pheweb.qq.json \
          --out_plot_type qq
        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
        resources:
          requests:
            cpu: 250m
            memory: 1Gi
          limits:
            cpu: 500m
            memory: 4Gi
      outputs:
        artifacts:
          - name: pheweb_manhattan_json
            path: "/mnt/vol/pheweb.manhattan.json"
            archive:
              none: {}
            s3:
              endpoint: s3.amazonaws.com
              bucket: "{{inputs.parameters.downloadable_bucket}}"
              key: "{{workflow.name}}/pheweb.manhattan.json"
          - name: pheweb_qq_json
            path: "/mnt/vol/pheweb.qq.json"
            archive:
              none: {}
            s3:
              endpoint: s3.amazonaws.com
              bucket: "{{inputs.parameters.downloadable_bucket}}"
              key: "{{workflow.name}}/pheweb.qq.json"

    # Archive outputs
    - name: archive-outputs
      inputs:
        parameters:
          - name: downloadable_bucket
        artifacts:
          - name: meta_analysis
            mode: 511
            path: "/mnt/vol/{{workflow.name}}/meta_analysis"
          - name: workflow_inputs_json
            path: "/mnt/vol/{{workflow.name}}/meta_analysis_inputs.json"
          - name: manhattan_plot
            path: "/mnt/vol/{{workflow.name}}/manhattan.png"
          - name: qq_plot
            path: "/mnt/vol/{{workflow.name}}/qq.png"
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"
      script:
        image: quay.io/cdis/post_gwas:0.0.9
        imagePullPolicy: IfNotPresent
        command: [/bin/bash]
        source: |
          echo "Bash version:"
          echo $(bash --version)

          echo "Locale:"
          echo $(locale)

          cd /mnt/vol/
          zip -r {{workflow.name}}.zip {{workflow.name}}/
        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
        resources:
          requests:
            cpu: 250m
            memory: 500Mi
          limits:
            cpu: 500m
            memory: 1Gi
      outputs:
        artifacts:
          - name: meta_analysis_archive
            path: "/mnt/vol/{{workflow.name}}.zip"
            archive:
              none: {}
            s3:
              endpoint: s3.amazonaws.com
              bucket: "{{inputs.parameters.downloadable_bucket}}" 
              key: "{{workflow.name}}/{{workflow.name}}.zip"

    # Create indexd records
    - name: create-indexd-record
      inputs:
        parameters:
          - name: arborist_resource
          - name: internal_api_env
          - name: downloadable_bucket
        artifacts:
          - name: meta_analysis_archive
            path: "/mnt/vol/{{workflow.name}}.zip"
          - name: pheweb_manhattan_json
            path: "/mnt/vol/pheweb.manhattan.json"
          - name: pheweb_qq_json
            path: "/mnt/vol/pheweb.qq.json"
      retryStrategy:
        limit: "3"
        retryPolicy: "Always"
      container:
        image: 707767160287.dkr.ecr.us-east-1.amazonaws.com/gen3/vadc-gwas-tools:1.2.7
        imagePullPolicy: IfNotPresent
        command: ["/bin/bash", "-c"]
        args: ["/env/bin/vadc-gwas-tools CreateIndexdRecord \
                --gwas_archive {{inputs.artifacts.meta_analysis_archive.path}} \
                --s3_uri s3://{{inputs.parameters.downloadable_bucket}}/{{workflow.name}}/{{workflow.name}}.zip \
                --arborist_resource {{inputs.parameters.arborist_resource}} \
                -o /mnt/vol/did_archive.json && \
                /env/bin/vadc-gwas-tools CreateIndexdRecord \
                --gwas_archive {{inputs.artifacts.pheweb_manhattan_json.path}} \
                --s3_uri s3://{{inputs.parameters.downloadable_bucket}}/{{workflow.name}}/pheweb.manhattan.json \
                --arborist_resource {{inputs.parameters.arborist_resource}} \
                -o /mnt/vol/did_pheweb_manhattan_json.json && \
                /env/bin/vadc-gwas-tools CreateIndexdRecord \
                --gwas_archive {{inputs.artifacts.pheweb_qq_json.path}} \
                --s3_uri s3://{{inputs.parameters.downloadable_bucket}}/{{workflow.name}}/pheweb.qq.json \
                --arborist_resource {{inputs.parameters.arborist_resource}} \
                -o /mnt/vol/did_pheweb_qq_json.json"]
        env:
          - name: GEN3_ENVIRONMENT
            value: "{{inputs.parameters.internal_api_env}}"
          - name: INDEXDUSER
            valueFrom:
              secretKeyRef:
                name: indexd-creds
                key: user
          - name: INDEXDPASS
            valueFrom:
              secretKeyRef:
                name: indexd-creds
                key: password
        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
        resources:
          requests:
            cpu: 50m
            memory: 50Mi
          limits:
            cpu: 100m
      outputs:
        parameters:
          # Use gwas_archive_index for now to test downloading from Results App
          # Rename to meta_archive_index once Results App UI supports it.
          - name: gwas_archive_index
            valueFrom:
              path: /mnt/vol/did_archive.json
            globalName: gwas_archive_index
          - name: pheweb_manhattan_json_index
            valueFrom:
              path: /mnt/vol/did_pheweb_manhattan_json.json
            globalName: pheweb_manhattan_json_index
          - name: pheweb_qq_json_index
            valueFrom:
              path: /mnt/vol/did_pheweb_qq_json.json
            globalName: pheweb_qq_json_index
